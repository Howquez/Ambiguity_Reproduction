{"title":"Pre-Processing","markdown":{"headingText":"Pre-Processing","containsRefs":false,"markdown":"\n<!-- git subtree push --prefix reproduction_package/rendered_documents origin gh-pages -->\n\nThis document explains how to process the raw data into a tidy format. We assume familiarity with our paper _(Ambiguity attitudes and surprises)_ and recommend to also read @Baillon_2018a to better understand the method we apply in this document.\n\n## Install Packages\n\nWe install the following packages using the `groundhog` package manager to increase computational reproducibility.\n\n```{r install_packages}\n#| output: false\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n    library(\"groundhog\")\n}\n\npkgs <- c(\"magrittr\", \"data.table\", \"stringr\", \"lubridate\", \"glue\", \"knitr\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2023-09-25\")\n```\n\n## Read Data\n\nWe read two data files. First, `raw`, that is, a raw data set containing all variables defined in [@oTree]. This is the data we are most interested in as it contains all of our behavioral measures [see @Baillon_2018a] and self-reports.^[Note that we removed three variables to maintain anonymity of participants: their reported zip codes as well as two open-text fields rather unrelated to this study.] Second, `time_spent` describes how much time each participant spent on a given page of the online experiment.\n\n```{r read_data}\nraw <- data.table::fread(file = \"../data/raw/all_apps_wide_2021-09-15.csv\",\n                         fill = TRUE)\n\ntime_spent <- data.table::fread(file = \"../data/raw/PageTimes-2021-09-15.csv\")\n```\n\n## Exclusion\n\nWe drop several rows of the `raw` data based on two conditions:\n\n1. We only want to keep observations that finished the survey (i.e., they reached the `_max_page_index`).\n2. We want to exclude rows created during testing and only keep those, where the `participant.label` is a 32-character alpha-numeric string provided by the sample provider.\n\n```{r exclusion}\nDT <- raw[participant._index_in_pages == participant._max_page_index & \n            nchar(participant.label) == 32]\n```\n\nThe result is assigned to a data.tabled called `DT`.\n\n## Primary Outcomes\n\nFollowing @Baillon_2018a, we study two indices capturing ambiguity attitudes:\n\n$$\nb=1-\\overline{m_s}-\\overline{m_c} \\qquad \\qquad a= 3 \\times (\\frac{1}{3} -(\\overline{m_c}-\\overline{m_s})).\n$$\n\nIndex _b_ captures the _ambiguity aversion_ and ranges from -1 to 1. A negative _b_ can be interpreted as ambiguity seeking, while a positive _b_ refers to ambiguity aversion: in fact, for expected utility maximizers, i.e., ambiguity-neutral decision makers, the probability equivalents of an event and its complement adds to 1 such that the index takes value 0.\n\nIndex _a_ is referred to as the _ambiguity-generating insensitivity index_. It measures to what extent the matching probabilities converge towards 50%. Again, it takes value 0 under ambiguity neutrality as $\\overline{m_s} = \\frac{1}{3}$ and $\\overline{m_c} = \\frac{2}{3}$. Positive values of _a_ indicate overweighted low probabilities and underweighted high probabilities, reflecting relative insensitivity. In contrast, negative values of _a_ indicate underweighted low probabilities and overweighted high probabilities [@AnantanasuwongEtAl_2019].\n\nFor the sake of convenience, we start to compute these indices by dropping all the columns that we do not need for this step and keep the `participant.id` to match the data later on. To do so, we use a regex.\n\n\n```{r select_data}\ncols <- str_detect(string = names(DT), \n                   pattern = \"participant.label|event_decision|matching_probability|Intro.1.player.(location|treatment)\")\n\ntmp <- DT[, ..cols]\n```\n\nWe then rename the two treatment variables, `surprise` and `communication`:\n\n```{r rename_treatment}\ntmp[, surprise := ifelse(test = Intro.1.player.location == 'Ilomantsi',\n                         yes  = TRUE,\n                         no   = FALSE)]\ntmp[, Intro.1.player.location := NULL]\n\nsetnames(x = tmp, old = 'Intro.1.player.treatment', new = 'communication')\ntmp[communication == \"best_guess\", communication := \"point\"]\n```\n\n```{r display_events}\ntmp %>% head(n = 7) %>% kable()\n```\n\nWe then use `data.table::melt()` to create a long table, create a `stage` as well as a `treated` variable that express treatment status. In addition, we correct matching probabilities equaling 101. Because the stated number of winning balls indicates the minimum number of balls such that the lottery is preferred, we subtract 0.5 from the selected values to specify the matching probability (indifference point)\n\n```{r reshape_long}\nlong <- data.table::melt(tmp,\n                         id.vars = c('participant.label', 'surprise', 'communication'),\n                         measure.vars = patterns('matching', 'decision'),\n                         variable.name = 'period',\n                         value.name = c('matching_prob', 'event'))\n\nlong[, period := period %>% as.character() %>% as.numeric()]\nlong[period <= 6, stage := 1]\nlong[period >  6, stage := 2]\nlong[stage == 1, treated := FALSE]\nlong[stage == 2, treated := TRUE]\n\nlong[, matching_prob := matching_prob %>% as.numeric()]\nlong[matching_prob != 101 & matching_prob != 0, matching_prob := matching_prob - 0.5]\nlong[matching_prob == 101, matching_prob := 100]\n```\n\n```{r display_long}\nlong %>% head(n = 7) %>% kable()\n```\n\nNext, we reshape that table once more and bring it to a wide format using `data.table::dcast()` and call the result `event_data`.\n\n```{r reshape_wide}\nevent_data <- data.table::dcast(long, \n                                participant.label + surprise + communication + stage + treated ~ event, \n                                value.var = c('matching_prob'))\n\nsetorder(event_data, surprise, communication, participant.label)\n```\n\nWe now change the data class of `communication` and make it a factor.\n\n```{r factorize}\nevent_data[, communication := as.factor(communication)]\nevent_data[, communication := factor(communication, levels = c(\"point\", \"interval\", \"both\"))]\n```\n\nFinally, we create the indices we are interested in (mainly `b` and `a`) as well as the Euclidyan distance (`ed`) between matching probabilities prior to and after treatment.\n\n```{r calc_indices}\nevent_data[, mc := (E12 + E13 + E23)/3/100]\nevent_data[, ms := (E1 + E2 + E3)/3/100]\nevent_data[, b := (1 - ms - mc)]\nevent_data[, a := 3 * (1/3 - (mc - ms))]\n```\n\n```{r euclidyan_distance}\nevent_data[, ed := sqrt(diff(E1)^2+diff(E2)^2+diff(E3)^2+diff(E12)^2+diff(E13)^2+diff(E23)^2), \n           by = participant.label]\n```\n\n```{r display_wide}\nevent_data %>% head(n = 7) %>% kable()\n```\n\n\n## Self-Reports\n\nFor the sake of clarity, we select self-reported columns as well as the `participant.label` while processing the self-reported data. Doing so, we exploit that all self-reports were elicited in the so called `Outro` app, which is why we can select the corresponding columns using oTree's naming convention.\n\n```{r select_self_report_columns}\nsr_cols <- c(\"participant.label\", \"participant.time_started_utc\", \n             names(DT) %>% \n               str_subset(pattern = \"Outro\")) %>%\n  str_subset(pattern = \"subsession|role|payoff|in_group\", \n             negate = TRUE)\n\nself_reports <- DT[, ..sr_cols]\n```\n\nTo increase clarity further, we drop irrelevant information from oTree's naming convention (e.g., replace the name of `Outro.1.player.Family` with _\"family\"_).\n\n```{r rename_self_report_columns}\nnames(self_reports) %>%\n  str_replace_all(pattern = \".*player\\\\.\", replacement = \"\") %>%\n  str_to_lower() %>%\n  setnames(x = self_reports)\n```\n\nNext, we dichotomize several self-reports using a median split.\n\n```{r median_splits}\nself_reports[, high_temperature := ifelse(test = temp >= median(temp),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_usage := ifelse(test = usage >= median(usage),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_general_risk := ifelse(test = risk_general >= median(risk_general),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_weather_risk := ifelse(test = risk_weather >= median(risk_weather),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_accuracy := ifelse(test = accuracy >= median(accuracy),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_credibility := ifelse(test = credibility >= median(credibility),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\n```\n\n\nIn addition, we hard-code some variables.\n\n```{r hard_code_age}\nself_reports[age < 18, age := NA]\n\nself_reports[, age_18_34   := ifelse(test = age < 35, yes = TRUE, no = FALSE)]\nself_reports[, age_53_plus := ifelse(age > 52, yes = TRUE, no = FALSE)]\nself_reports[, age_35_52   := ifelse(age >= 35 & age <= 52, yes = TRUE, no = FALSE)]\n```\n\n```{r hard_code_gender}\nself_reports[, female := ifelse(test = gender == \"female\", yes = TRUE, no = FALSE)]\n```\n\n```{r hard_code_education}\nself_reports[, high_education := ifelse(test = education >= 5, yes = TRUE, no = FALSE)]\nself_reports[, high_education := ifelse(test = education == 8, yes = FALSE, no = high_education)]\n```\n\n```{r hard_code_income}\nself_reports[income == 99999, income := NA]\nself_reports[, high_income := ifelse(test = income >= 3, yes = TRUE, no = FALSE)]\n```\n\n```{r hard_code_family}\nself_reports[, married := ifelse(test = family == \"same-sex union\" | family == \"married\", yes = TRUE, no = FALSE)]\n```\n\n```{r select_new_vars_in_self_reports}\nself_report_selection <- self_reports[, .(participant.label,\n                                          participant.time_started_utc,\n                                          comprehension,\n                                          age_18_34,\n                                          age_35_52,\n                                          age_53_plus,\n                                          female,\n                                          high_education,\n                                          high_income,\n                                          married,\n                                          parentship = as.logical(kids),\n                                          high_temperature,\n                                          high_usage,\n                                          high_general_risk,\n                                          high_weather_risk,\n                                          high_accuracy,\n                                          high_credibility, \n                                          credibility)]\n```\n\n```{r display_self_reports}\nself_report_selection %>% head(n = 7) %>% kable()\n```\n\n## Comprehension Questions\n\nFor robustness checks, we subset participants, who did answer the comprehension questions correctly at their first try. These information are stored in the `Intro` app, which we now select and rename before we merge it with the remaining data later on.\n\n```{r select_wrong_answers}\nintro <- names(DT) %>% \n  str_detect(pattern = \"participant.label|wrong\")\n\ncomp_questions <- DT[, ..intro]\n```\n\n\n```{r rename_wrong_answers}\nnames(comp_questions) %>%\n  str_replace_all(pattern = \".*player\\\\.\", replacement = \"\") %>%\n  str_to_lower() %>%\n  setnames(x = comp_questions)\n```\n\n\n## Time Spent\n\nNext, we calculate how much time a participant spent on a given page. To do so, we subtract time stamps which were recorded whenever a page was submitted. The difference of two subsequent time stamps (`time_spent_on_page`) therefore tells us how much time a participant spent on a given page.\n\nWe calculate the `time_spent_on_page` metric, store it in a data table `duration` and add a `participant.label` column that is not inherent to the available `time_spent` data (and which we use as the key ID to match data).\n\n```{r time_spent}\ntime_spent[,\n          lag := shift(epoch_time_completed, fill = NA, type = \"lag\"),\n          by = c(\"session_code\", \"participant_code\")]\n\ntime_spent[,\n          time_spent_on_page := epoch_time_completed - lag,\n          by = c(\"session_code\", \"participant_code\")]\n\ntime_spent[,\n          completion := epoch_time_completed %>% max() - epoch_time_completed %>% min(),\n          by = c(\"session_code\", \"participant_code\")]\n\nduration <- time_spent[participant_code %in% DT$participant.code,\n                      .(\n                        session_code,\n                        participant.code = participant_code,\n                        app_name,\n                        page_name,\n                        page_index,\n                        page_submission = epoch_time_completed,\n                        time_spent_on_page,\n                        completion_time = completion\n                      )] %>%\n  setorder(participant.code, page_index)\n\nduration <- duration[DT[, .(participant.label, participant.code)],\n                     on = .(participant.code = participant.code)]\n```\n\n```{r display_duration}\nduration %>% head(n = 7) %>% kable()\n```\n\n## Merge Data\n\n```{r merge_data}\nmerge_1 <- event_data[duration[, .(participant.label, participant.code, completion_time)] %>% unique(),\n                      on = .(participant.label)]\n\nmerge_2 <- merge_1[comp_questions,\n                   on = .(participant.label)]\n\nfull_processed <- merge_2[self_report_selection, \n                          on = .(participant.label = participant.label)]\n```\n\n```{r display_full_data}\nfull_processed %>% head(n = 7) %>% kable()\n```\n\n\n## Save Data\n\nWe will save the data in two formats: R's native `Rda` as well as the more interoperable `csv` format.  We noticed that the floats have fewer digits when writing `csv` files compared to `Rda`s. We'll therefor load the latter format thoughout the following sections.\n\n```{r save_data}\ndata.table::fwrite(x = full_processed,\n                   file = \"../data/processed/full.csv\")\nsaveRDS(full_processed, file = \"../data/processed/full.Rda\")\n\ndata.table::fwrite(x = duration,\n                   file = \"../data/processed/timing.csv\")\nsaveRDS(duration, file = \"../data/processed/timing.Rda\")\n```\n\n## Clean up\n\nLastly, we clean the global environment.\n\n```{r cleanup}\nobjects <- c(ls(), \"objects\", \"objects_to_keep\", \"objects_to_remove\")\nobjects_to_keep <- c(\"full_processed\", \"duration\")\nobjects_to_remove <- setdiff(objects, objects_to_keep)\nrm(list = objects_to_remove)\n```\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","embed-resources":true,"output-file":"01-pre-processing.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.132","bibliography":["references.bib"],"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}}}
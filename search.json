[
  {
    "objectID": "01-pre-processing.html#install-packages",
    "href": "01-pre-processing.html#install-packages",
    "title": "1  Pre-Processing",
    "section": "1.1 Install Packages",
    "text": "1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"lubridate\", \"glue\", \"knitr\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)"
  },
  {
    "objectID": "01-pre-processing.html#read-data",
    "href": "01-pre-processing.html#read-data",
    "title": "1  Pre-Processing",
    "section": "1.2 Read Data",
    "text": "1.2 Read Data\nWe read two data files. First, raw, that is, a raw data set containing all variables defined in (Chen, Schonger, and Wickens 2016). This is the data we are most interested in as it contains all of our behavioral measures (see Baillon et al. 2018) and self-reports. Second, time_spent describes how much time each participant spent on a given page of the online experiment.\nIn a first step, we remove three variables from the raw data to maintain anonymity of participants: their reported zip codes as well as two open-text fields rather unrelated to this study.\n\ndt &lt;- data.table::fread(file = \"../data/raw/all_apps_wide_2021-09-15.csv\",\n                         fill = TRUE)\n\ncols &lt;- str_subset(string = names(dt),\n                   pattern = \"CLICCS\\\\d$|ZIP$\",\n                   negate = TRUE)\n\ndata.table::fwrite(x = dt[, ..cols],\n                   file = \"../data/raw/all_apps_wide_2021-09-15-without-ZIP.csv\",\n                   sep = \";\")\n\nNote that we will not provide the raw data ../data/raw/all_apps_wide_2021-09-15.csv but the slightly trimmed raw data instead ../data/raw/all_apps_wide_2021-09-15-without-ZIP.csv. A computational reproduction of or work therefore starts with the following code chunk.\n\nraw &lt;- data.table::fread(file = \"../data/raw/all_apps_wide_2021-09-15-without-ZIP.csv\",\n                         sep = \";\",\n                         fill = TRUE)\n\ntime_spent &lt;- data.table::fread(file = \"../data/raw/PageTimes-2021-09-15.csv\")"
  },
  {
    "objectID": "01-pre-processing.html#exclusion",
    "href": "01-pre-processing.html#exclusion",
    "title": "1  Pre-Processing",
    "section": "1.3 Exclusion",
    "text": "1.3 Exclusion\nWe drop several rows of the raw data based on two conditions:\n\nWe only want to keep observations that finished the survey (i.e., they reached the _max_page_index).\nWe want to exclude rows created during testing and only keep those, where the participant.label is a 32-character alpha-numeric string provided by the sample provider.\n\n\nDT &lt;- raw[participant._index_in_pages == participant._max_page_index & \n            nchar(participant.label) == 32]\n\nThe result is assigned to a data.tabled called DT."
  },
  {
    "objectID": "01-pre-processing.html#primary-outcomes",
    "href": "01-pre-processing.html#primary-outcomes",
    "title": "1  Pre-Processing",
    "section": "1.4 Primary Outcomes",
    "text": "1.4 Primary Outcomes\nFollowing Baillon et al. (2018), we study two indices capturing ambiguity attitudes:\n\\[\nb=1-\\overline{m_s}-\\overline{m_c} \\qquad \\qquad a= 3 \\times (\\frac{1}{3} -(\\overline{m_c}-\\overline{m_s})).\n\\]\nIndex b captures the ambiguity aversion and ranges from -1 to 1. A negative b can be interpreted as ambiguity seeking, while a positive b refers to ambiguity aversion: in fact, for expected utility maximizers, i.e., ambiguity-neutral decision makers, the probability equivalents of an event and its complement adds to 1 such that the index takes value 0.\nIndex a is referred to as the ambiguity-generating insensitivity index. It measures to what extent the matching probabilities converge towards 50%. Again, it takes value 0 under ambiguity neutrality as \\(\\overline{m_s} = \\frac{1}{3}\\) and \\(\\overline{m_c} = \\frac{2}{3}\\). Positive values of a indicate overweighted low probabilities and underweighted high probabilities, reflecting relative insensitivity. In contrast, negative values of a indicate underweighted low probabilities and overweighted high probabilities (Anantanasuwong et al. 2019).\nFor the sake of convenience, we start to compute these indices by dropping all the columns that we do not need for this step and keep the participant.id to match the data later on. To do so, we use a regex.\n\ncols &lt;- str_detect(string = names(DT), \n                   pattern = \"participant.label|event_decision|matching_probability|Intro.1.player.(location|treatment)\")\n\ntmp &lt;- DT[, ..cols]\n\nWe then rename the two treatment variables, surprise and communication:\n\ntmp[, surprise := ifelse(test = Intro.1.player.location == 'Ilomantsi',\n                         yes  = TRUE,\n                         no   = FALSE)]\ntmp[, Intro.1.player.location := NULL]\n\nsetnames(x = tmp, old = 'Intro.1.player.treatment', new = 'communication')\ntmp[communication == \"best_guess\", communication := \"point\"]\n\n\ntmp %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant.label\ncommunication\nBaillon.1.player.matching_probability\nBaillon.1.player.event_decision\nBaillon.2.player.matching_probability\nBaillon.2.player.event_decision\nBaillon.3.player.matching_probability\nBaillon.3.player.event_decision\nBaillon.4.player.matching_probability\nBaillon.4.player.event_decision\nBaillon.5.player.matching_probability\nBaillon.5.player.event_decision\nBaillon.6.player.matching_probability\nBaillon.6.player.event_decision\nBaillon.7.player.matching_probability\nBaillon.7.player.event_decision\nBaillon.8.player.matching_probability\nBaillon.8.player.event_decision\nBaillon.9.player.matching_probability\nBaillon.9.player.event_decision\nBaillon.10.player.matching_probability\nBaillon.10.player.event_decision\nBaillon.11.player.matching_probability\nBaillon.11.player.event_decision\nBaillon.12.player.matching_probability\nBaillon.12.player.event_decision\nsurprise\n\n\n\n\n0e379132b6dab27b63921c941312840f\ninterval\n67\nE13\n67\nE12\n34\nE1\n67\nE23\n34\nE3\n34\nE2\n66\nE13\n67\nE12\n34\nE1\n67\nE23\n34\nE3\n34\nE2\nTRUE\n\n\nca48f818955f9a22b31d290dc2a28723\nboth\n70\nE23\n70\nE12\n40\nE2\n7\nE13\n40\nE3\n40\nE1\n70\nE23\n70\nE12\n40\nE2\n70\nE13\n40\nE3\n40\nE1\nTRUE\n\n\n6ccf7afc080efce8a5d08fe2b3547b3e\ninterval\n45\nE23\n55\nE2\n45\nE12\n40\nE3\n35\nE13\n55\nE1\n30\nE23\n60\nE2\n40\nE12\n55\nE3\n60\nE13\n65\nE1\nFALSE\n\n\n50a040bc4e4e9266a0f40b85fd4e4d0e\nboth\n51\nE12\n51\nE3\n51\nE2\n67\nE13\n51\nE1\n67\nE23\n80\nE12\n67\nE3\n80\nE2\n67\nE13\n51\nE1\n67\nE23\nTRUE\n\n\nc1709a48b7d3e4a55aeaf6feb55eaf69\nboth\n50\nE2\n55\nE1\n50\nE12\n45\nE13\n60\nE3\n58\nE23\n45\nE2\n47\nE1\n50\nE12\n55\nE13\n40\nE3\n52\nE23\nFALSE\n\n\n79c8aa8a670d96b4afb54af9fca6e6a8\nboth\n45\nE1\n56\nE12\n46\nE2\n63\nE23\n58\nE13\n47\nE3\n43\nE1\n54\nE12\n49\nE2\n67\nE23\n59\nE13\n45\nE3\nFALSE\n\n\n0c42458206b38f6b28125c23ac8fbd8b\ninterval\n70\nE13\n67\nE12\n65\nE3\n80\nE23\n50\nE2\n45\nE1\n50\nE13\n50\nE12\n50\nE3\n67\nE23\n65\nE2\n30\nE1\nFALSE\n\n\n\n\n\nWe then use data.table::melt() to create a long table, create a stage as well as a treated variable that express treatment status. In addition, we correct matching probabilities equaling 101. Because the stated number of winning balls indicates the minimum number of balls such that the lottery is preferred, we subtract 0.5 from the selected values to specify the matching probability (indifference point)\n\nlong &lt;- data.table::melt(tmp,\n                         id.vars = c('participant.label', 'surprise', 'communication'),\n                         measure.vars = patterns('matching', 'decision'),\n                         variable.name = 'period',\n                         value.name = c('matching_prob', 'event'))\n\nlong[, period := period %&gt;% as.character() %&gt;% as.numeric()]\nlong[period &lt;= 6, stage := 1]\nlong[period &gt;  6, stage := 2]\nlong[stage == 1, treated := FALSE]\nlong[stage == 2, treated := TRUE]\n\nlong[, matching_prob := matching_prob %&gt;% as.numeric()]\nlong[matching_prob != 101 & matching_prob != 0, matching_prob := matching_prob - 0.5]\nlong[matching_prob == 101, matching_prob := 100]\n\n\nlong %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant.label\nsurprise\ncommunication\nperiod\nmatching_prob\nevent\nstage\ntreated\n\n\n\n\n0e379132b6dab27b63921c941312840f\nTRUE\ninterval\n1\n66.5\nE13\n1\nFALSE\n\n\nca48f818955f9a22b31d290dc2a28723\nTRUE\nboth\n1\n69.5\nE23\n1\nFALSE\n\n\n6ccf7afc080efce8a5d08fe2b3547b3e\nFALSE\ninterval\n1\n44.5\nE23\n1\nFALSE\n\n\n50a040bc4e4e9266a0f40b85fd4e4d0e\nTRUE\nboth\n1\n50.5\nE12\n1\nFALSE\n\n\nc1709a48b7d3e4a55aeaf6feb55eaf69\nFALSE\nboth\n1\n49.5\nE2\n1\nFALSE\n\n\n79c8aa8a670d96b4afb54af9fca6e6a8\nFALSE\nboth\n1\n44.5\nE1\n1\nFALSE\n\n\n0c42458206b38f6b28125c23ac8fbd8b\nFALSE\ninterval\n1\n69.5\nE13\n1\nFALSE\n\n\n\n\n\nNext, we reshape that table once more and bring it to a wide format using data.table::dcast() and call the result event_data.\n\nevent_data &lt;- data.table::dcast(long, \n                                participant.label + surprise + communication + stage + treated ~ event, \n                                value.var = c('matching_prob'))\n\nsetorder(event_data, surprise, communication, participant.label)\n\nWe now change the data class of communication and make it a factor.\n\nevent_data[, communication := as.factor(communication)]\nevent_data[, communication := factor(communication, levels = c(\"point\", \"both\", \"interval\"))]\n\nevent_data[, stage := as.factor(stage)]\nevent_data[, stage := factor(stage, \n                             levels = c(\"1\", \"2\"))]\n\nFinally, we create the indices we are interested in (mainly b and a) as well as the Euclidyan distance (ed) between matching probabilities prior to and after treatment.\n\nevent_data[, mc := (E12 + E13 + E23)/3/100]\nevent_data[, ms := (E1 + E2 + E3)/3/100]\nevent_data[, b := (1 - ms - mc)]\nevent_data[, a := 3 * (1/3 - (mc - ms))]\n\n\nevent_data[, ed := sqrt(diff(E1)^2+diff(E2)^2+diff(E3)^2+diff(E12)^2+diff(E13)^2+diff(E23)^2), \n           by = participant.label]\n\n\nevent_data %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant.label\nsurprise\ncommunication\nstage\ntreated\nE1\nE12\nE13\nE2\nE23\nE3\nmc\nms\nb\na\ned\n\n\n\n\n01c4f6a51f1a756640eaa8c97302edc8\nFALSE\nboth\n1\nFALSE\n49.5\n49.5\n69.5\n33.5\n66.5\n35.5\n0.6183333\n0.3950000\n-0.0133333\n0.33\n60.38212\n\n\n01c4f6a51f1a756640eaa8c97302edc8\nFALSE\nboth\n2\nTRUE\n9.5\n74.5\n39.5\n49.5\n69.5\n19.5\n0.6116667\n0.2616667\n0.1266667\n-0.05\n60.38212\n\n\n026c74f9a6c56e375ee0f248c2a13ff0\nFALSE\nboth\n1\nFALSE\n33.5\n66.5\n66.5\n33.5\n66.5\n33.5\n0.6650000\n0.3350000\n0.0000000\n0.01\n0.00000\n\n\n026c74f9a6c56e375ee0f248c2a13ff0\nFALSE\nboth\n2\nTRUE\n33.5\n66.5\n66.5\n33.5\n66.5\n33.5\n0.6650000\n0.3350000\n0.0000000\n0.01\n0.00000\n\n\n0403e88278229630e892f8887fe351a8\nFALSE\nboth\n1\nFALSE\n59.5\n74.5\n49.5\n49.5\n64.5\n69.5\n0.6283333\n0.5950000\n-0.2233333\n0.90\n38.07887\n\n\n0403e88278229630e892f8887fe351a8\nFALSE\nboth\n2\nTRUE\n49.5\n49.5\n69.5\n49.5\n79.5\n59.5\n0.6616667\n0.5283333\n-0.1900000\n0.60\n38.07887\n\n\n041ed5ab429aeb34d1c0c8da5d3d2ec8\nFALSE\nboth\n1\nFALSE\n84.5\n49.5\n49.5\n49.5\n49.5\n39.5\n0.4950000\n0.5783333\n-0.0733333\n1.25\n40.62019"
  },
  {
    "objectID": "01-pre-processing.html#self-reports",
    "href": "01-pre-processing.html#self-reports",
    "title": "1  Pre-Processing",
    "section": "1.5 Self-Reports",
    "text": "1.5 Self-Reports\nFor the sake of clarity, we select self-reported columns as well as the participant.label while processing the self-reported data. Doing so, we exploit that all self-reports were elicited in the so called Outro app, which is why we can select the corresponding columns using oTree’s naming convention.\n\nsr_cols &lt;- c(\"participant.label\", \"participant.time_started_utc\", \n             names(DT) %&gt;% \n               str_subset(pattern = \"Outro\")) %&gt;%\n  str_subset(pattern = \"subsession|role|payoff|in_group\", \n             negate = TRUE)\n\nself_reports &lt;- DT[, ..sr_cols]\n\nTo increase clarity further, we drop irrelevant information from oTree’s naming convention (e.g., replace the name of Outro.1.player.Family with “family”).\n\nnames(self_reports) %&gt;%\n  str_replace_all(pattern = \".*player\\\\.\", replacement = \"\") %&gt;%\n  str_to_lower() %&gt;%\n  setnames(x = self_reports)\n\nNext, we dichotomize several self-reports using a median split.\n\nself_reports[, high_temperature := ifelse(test = temp &gt;= median(temp),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_usage := ifelse(test = usage &gt;= median(usage),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_general_risk := ifelse(test = risk_general &gt;= median(risk_general),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_weather_risk := ifelse(test = risk_weather &gt;= median(risk_weather),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_accuracy := ifelse(test = accuracy &gt;= median(accuracy),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nself_reports[, high_credibility := ifelse(test = credibility &gt;= median(credibility),\n                                          yes  = TRUE,\n                                          no   = FALSE)]\n\nIn addition, we hard-code some variables.\n\nself_reports[age &lt; 18, age := NA]\n\nself_reports[, age_18_34   := ifelse(test = age &lt; 35, yes = TRUE, no = FALSE)]\nself_reports[, age_53_plus := ifelse(age &gt; 52, yes = TRUE, no = FALSE)]\nself_reports[, age_35_52   := ifelse(age &gt;= 35 & age &lt;= 52, yes = TRUE, no = FALSE)]\n\n\nself_reports[, female := ifelse(test = gender == \"female\", yes = TRUE, no = FALSE)]\n\n\nself_reports[, high_education := ifelse(test = education &gt;= 5, yes = TRUE, no = FALSE)]\nself_reports[, high_education := ifelse(test = education == 8, yes = FALSE, no = high_education)]\n\n\nself_reports[income == 99999, income := NA]\nself_reports[, high_income := ifelse(test = income &gt;= 3, yes = TRUE, no = FALSE)]\n\n\nself_reports[, married := ifelse(test = family == \"same-sex union\" | family == \"married\", yes = TRUE, no = FALSE)]\n\n\nself_report_selection &lt;- self_reports[, .(participant.label,\n                                          participant.time_started_utc,\n                                          comprehension,\n                                          age_18_34,\n                                          age_35_52,\n                                          age_53_plus,\n                                          female,\n                                          high_education,\n                                          high_income,\n                                          married,\n                                          parentship = as.logical(kids),\n                                          high_temperature,\n                                          high_usage,\n                                          high_general_risk,\n                                          high_weather_risk,\n                                          high_accuracy,\n                                          high_credibility,\n                                          temperature = temp,\n                                          usage,\n                                          general_risk = risk_general,\n                                          weather_risk = risk_weather,\n                                          accuracy,\n                                          credibility)]\n\n\nself_report_selection %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant.label\nparticipant.time_started_utc\ncomprehension\nage_18_34\nage_35_52\nage_53_plus\nfemale\nhigh_education\nhigh_income\nmarried\nparentship\nhigh_temperature\nhigh_usage\nhigh_general_risk\nhigh_weather_risk\nhigh_accuracy\nhigh_credibility\ntemperature\nusage\ngeneral_risk\nweather_risk\naccuracy\ncredibility\n\n\n\n\n0e379132b6dab27b63921c941312840f\n2021-09-02 11:06:03\nrather yes\nFALSE\nTRUE\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\n17\n4\n0\n4\n2\n2\n\n\nca48f818955f9a22b31d290dc2a28723\n2021-09-02 11:22:18\nrather yes\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n20\n3\n5\n8\n2\n3\n\n\n6ccf7afc080efce8a5d08fe2b3547b3e\n2021-09-02 11:25:21\nrather yes\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n21\n3\n6\n7\n2\n3\n\n\n50a040bc4e4e9266a0f40b85fd4e4d0e\n2021-09-02 11:36:03\nrather yes\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\n17\n3\n3\n7\n1\n2\n\n\nc1709a48b7d3e4a55aeaf6feb55eaf69\n2021-09-02 11:47:01\nrather not\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\n20\n2\n0\n0\n2\n2\n\n\n79c8aa8a670d96b4afb54af9fca6e6a8\n2021-09-02 11:52:48\nrather yes\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\n20\n5\n5\n0\n1\n3\n\n\n0c42458206b38f6b28125c23ac8fbd8b\n2021-09-02 12:08:26\nyes\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\nFALSE\n23\n4\n8\n7\n2\n2"
  },
  {
    "objectID": "01-pre-processing.html#comprehension-questions",
    "href": "01-pre-processing.html#comprehension-questions",
    "title": "1  Pre-Processing",
    "section": "1.6 Comprehension Questions",
    "text": "1.6 Comprehension Questions\nFor robustness checks, we subset participants, who did answer the comprehension questions correctly at their first try. These information are stored in the Intro app, which we now select and rename before we merge it with the remaining data later on.\n\nintro &lt;- names(DT) %&gt;% \n  str_detect(pattern = \"participant.label|wrong\")\n\ncomp_questions &lt;- DT[, ..intro]\n\n\nnames(comp_questions) %&gt;%\n  str_replace_all(pattern = \".*player\\\\.\", replacement = \"\") %&gt;%\n  str_to_lower() %&gt;%\n  setnames(x = comp_questions)"
  },
  {
    "objectID": "01-pre-processing.html#time-spent",
    "href": "01-pre-processing.html#time-spent",
    "title": "1  Pre-Processing",
    "section": "1.7 Time Spent",
    "text": "1.7 Time Spent\nNext, we calculate how much time a participant spent on a given page. To do so, we subtract time stamps which were recorded whenever a page was submitted. The difference of two subsequent time stamps (time_spent_on_page) therefore tells us how much time a participant spent on a given page.\nWe calculate the time_spent_on_page metric, store it in a data table duration and add a participant.label column that is not inherent to the available time_spent data (and which we use as the key ID to match data).\n\ntime_spent[,\n          lag := shift(epoch_time_completed, fill = NA, type = \"lag\"),\n          by = c(\"session_code\", \"participant_code\")]\n\ntime_spent[,\n          time_spent_on_page := epoch_time_completed - lag,\n          by = c(\"session_code\", \"participant_code\")]\n\ntime_spent[,\n          completion := epoch_time_completed %&gt;% max() - epoch_time_completed %&gt;% min(),\n          by = c(\"session_code\", \"participant_code\")]\n\nduration &lt;- time_spent[participant_code %in% DT$participant.code,\n                      .(\n                        session_code,\n                        participant.code = participant_code,\n                        app_name,\n                        page_name,\n                        page_index,\n                        page_submission = epoch_time_completed,\n                        time_spent_on_page,\n                        completion_time = completion\n                      )] %&gt;%\n  setorder(participant.code, page_index)\n\nduration &lt;- duration[DT[, .(participant.label, participant.code)],\n                     on = .(participant.code = participant.code)]\n\n\nduration %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsession_code\nparticipant.code\napp_name\npage_name\npage_index\npage_submission\ntime_spent_on_page\ncompletion_time\nparticipant.label\n\n\n\n\nt2ciiflg\nlcsgtdi5\n\nInitializeParticipant\n0\n1630580763\nNA\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nIntro\nIntro_Welcome\n1\n1630580772\n9\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nIntro\nIntro_Instructions\n2\n1630581577\n805\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nBaillon\nBaillon_Decision\n3\n1630581718\n141\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nBaillon\nBaillon_Decision\n4\n1630581736\n18\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nBaillon\nBaillon_Decision\n5\n1630581745\n9\n1220\n0e379132b6dab27b63921c941312840f\n\n\nt2ciiflg\nlcsgtdi5\nBaillon\nBaillon_Decision\n6\n1630581755\n10\n1220\n0e379132b6dab27b63921c941312840f"
  },
  {
    "objectID": "01-pre-processing.html#merge-data",
    "href": "01-pre-processing.html#merge-data",
    "title": "1  Pre-Processing",
    "section": "1.8 Merge Data",
    "text": "1.8 Merge Data\n\nmerge_1 &lt;- event_data[duration[, .(participant.label, participant.code, completion_time)] %&gt;% unique(),\n                      on = .(participant.label)]\n\nmerge_2 &lt;- merge_1[comp_questions,\n                   on = .(participant.label)]\n\nfull_processed &lt;- merge_2[self_report_selection, \n                          on = .(participant.label = participant.label)]\n\n\nfull_processed %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant.label\nsurprise\ncommunication\nstage\ntreated\nE1\nE12\nE13\nE2\nE23\nE3\nmc\nms\nb\na\ned\nparticipant.code\ncompletion_time\nwrong_answer_1\nwrong_answer_2\nparticipant.time_started_utc\ncomprehension\nage_18_34\nage_35_52\nage_53_plus\nfemale\nhigh_education\nhigh_income\nmarried\nparentship\nhigh_temperature\nhigh_usage\nhigh_general_risk\nhigh_weather_risk\nhigh_accuracy\nhigh_credibility\ntemperature\nusage\ngeneral_risk\nweather_risk\naccuracy\ncredibility\n\n\n\n\n0e379132b6dab27b63921c941312840f\nTRUE\ninterval\n1\nFALSE\n33.5\n66.5\n66.5\n33.5\n66.5\n33.5\n0.6650000\n0.335\n0.0000000\n0.01\n1.00000\nlcsgtdi5\n1220\n6\n6\n2021-09-02 11:06:03\nrather yes\nFALSE\nTRUE\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\n17\n4\n0\n4\n2\n2\n\n\n0e379132b6dab27b63921c941312840f\nTRUE\ninterval\n2\nTRUE\n33.5\n66.5\n65.5\n33.5\n66.5\n33.5\n0.6616667\n0.335\n0.0033333\n0.02\n1.00000\nlcsgtdi5\n1220\n6\n6\n2021-09-02 11:06:03\nrather yes\nFALSE\nTRUE\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\n17\n4\n0\n4\n2\n2\n\n\nca48f818955f9a22b31d290dc2a28723\nTRUE\nboth\n1\nFALSE\n39.5\n69.5\n6.5\n39.5\n69.5\n39.5\n0.4850000\n0.395\n0.1200000\n0.73\n63.00000\na437aind\n750\n0\n0\n2021-09-02 11:22:18\nrather yes\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n20\n3\n5\n8\n2\n3\n\n\nca48f818955f9a22b31d290dc2a28723\nTRUE\nboth\n2\nTRUE\n39.5\n69.5\n69.5\n39.5\n69.5\n39.5\n0.6950000\n0.395\n-0.0900000\n0.10\n63.00000\na437aind\n750\n0\n0\n2021-09-02 11:22:18\nrather yes\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n20\n3\n5\n8\n2\n3\n\n\n6ccf7afc080efce8a5d08fe2b3547b3e\nFALSE\ninterval\n1\nFALSE\n54.5\n44.5\n34.5\n54.5\n44.5\n39.5\n0.4116667\n0.495\n0.0933333\n1.25\n35.00000\nqyi19xga\n3094\n0\n0\n2021-09-02 11:25:21\nrather yes\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n21\n3\n6\n7\n2\n3\n\n\n6ccf7afc080efce8a5d08fe2b3547b3e\nFALSE\ninterval\n2\nTRUE\n64.5\n39.5\n59.5\n59.5\n29.5\n54.5\n0.4283333\n0.595\n-0.0233333\n1.50\n35.00000\nqyi19xga\n3094\n0\n0\n2021-09-02 11:25:21\nrather yes\nFALSE\nTRUE\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nTRUE\nTRUE\n21\n3\n6\n7\n2\n3\n\n\n50a040bc4e4e9266a0f40b85fd4e4d0e\nTRUE\nboth\n1\nFALSE\n50.5\n50.5\n66.5\n50.5\n66.5\n50.5\n0.6116667\n0.505\n-0.1166667\n0.68\n44.02272\na0j9jcsg\n1224\n0\n0\n2021-09-02 11:36:03\nrather yes\nFALSE\nTRUE\nFALSE\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\n17\n3\n3\n7\n1\n2"
  },
  {
    "objectID": "01-pre-processing.html#save-data",
    "href": "01-pre-processing.html#save-data",
    "title": "1  Pre-Processing",
    "section": "1.9 Save Data",
    "text": "1.9 Save Data\nWe will save the data in two formats: R’s native Rda as well as the more interoperable csv format. We noticed that the floats have fewer digits when writing csv files compared to Rdas. We’ll therefor load the latter format throughout the following sections.\n\ndata.table::fwrite(x = full_processed,\n                   file = \"../data/processed/full.csv\")\nsaveRDS(full_processed, file = \"../data/processed/full.Rda\")\n\ndata.table::fwrite(x = duration,\n                   file = \"../data/processed/timing.csv\")\nsaveRDS(duration, file = \"../data/processed/timing.Rda\")"
  },
  {
    "objectID": "01-pre-processing.html#clean-up",
    "href": "01-pre-processing.html#clean-up",
    "title": "1  Pre-Processing",
    "section": "1.10 Clean up",
    "text": "1.10 Clean up\nLastly, we clean the global environment.\n\nobjects &lt;- c(ls(), \"objects\", \"objects_to_keep\", \"objects_to_remove\")\nobjects_to_keep &lt;- c(\"full_processed\", \"duration\")\nobjects_to_remove &lt;- setdiff(objects, objects_to_keep)\nrm(list = objects_to_remove)"
  },
  {
    "objectID": "01-pre-processing.html#footnotes",
    "href": "01-pre-processing.html#footnotes",
    "title": "1  Pre-Processing",
    "section": "",
    "text": "Note that we removed three variables to maintain anonymity of participants: their reported zip codes as well as two open-text fields rather unrelated to this study.↩︎"
  },
  {
    "objectID": "02-tables.html",
    "href": "02-tables.html",
    "title": "2  Tables",
    "section": "",
    "text": "3 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"lubridate\", \"knitr\", \n          \"sandwich\", \"lmtest\",\n          \"sjPlot\", \"stargazer\", \"gt\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)"
  },
  {
    "objectID": "02-tables.html#read-data",
    "href": "02-tables.html#read-data",
    "title": "2  Tables",
    "section": "3.1 Read Data",
    "text": "3.1 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")"
  },
  {
    "objectID": "02-tables.html#table-1",
    "href": "02-tables.html#table-1",
    "title": "2  Tables",
    "section": "3.2 Table 1",
    "text": "3.2 Table 1\n\n# data[communication == 'best_guess' & surprise == TRUE, .(mean = mean(a), \n#          sd = sd(a)), \n#      by = stage] %&gt;% \n#   round(digits = 2)"
  },
  {
    "objectID": "02-tables.html#table-3",
    "href": "02-tables.html#table-3",
    "title": "2  Tables",
    "section": "3.3 Table 3",
    "text": "3.3 Table 3\n\nols_3_1 &lt;- lm(formula = b ~ age_35_52 + age_53_plus + female + high_education + high_income + \n    married + parentship, \n            data = data, \n            subset = (treated == FALSE))\nse_3_1  &lt;- coeftest(ols_3_1, vcov = vcovHC(ols_3_1, type = \"HC1\"))\n\nols_3_2 &lt;- lm(formula = b ~ age_35_52 + age_53_plus + female + high_education + high_income + \n    married + parentship + high_temperature + high_usage + high_general_risk + \n    high_weather_risk + high_accuracy + high_credibility, \n            data = data, \n            subset = (treated == FALSE))\nse_3_2  &lt;- coeftest(ols_3_2, vcov = vcovHC(ols_3_2, type = \"HC1\"))\n\nols_3_3 &lt;- lm(formula = a ~ age_35_52 + age_53_plus + female + high_education + high_income + \n    married + parentship, \n            data = data, \n            subset = (treated == FALSE))\nse_3_3  &lt;- coeftest(ols_3_3, vcov = vcovHC(ols_3_3, type = \"HC1\"))\n\nols_3_4 &lt;- lm(formula = a ~ age_35_52 + age_53_plus + female + high_education + high_income + \n    married + parentship + high_temperature + high_usage + high_general_risk + \n    high_weather_risk + high_accuracy + high_credibility, \n            data = data, \n            subset = (treated == FALSE))\nse_3_4  &lt;- coeftest(ols_3_4, vcov = vcovHC(ols_3_4, type = \"HC1\"))\n\nse_3 &lt;- list(se_3_1[,2], se_3_2[,2], se_3_3[,2], se_3_4[,2])\np_3  &lt;- list(se_3_1[,4], se_3_2[,4], se_3_3[,4], se_3_4[,4])\n\nstargazer(ols_3_1, ols_3_2, ols_3_3, ols_3_4, \n          align = TRUE, \n          se = se_3, \n          p = p_3,   \n          title = \"Linear regressions: Explanatory analysis of Ambiguity Indices b and a\",\n          covariate.labels = c(\"age(35-52)\",\n                               \"age(53-69)\",\n                               \"gender (female)\",\n                               \"high education\",\n                               \"high income\",\n                               \"family (married or same sex union)\",\n                               \"parentship\",\n                               \"high temperature (median)\",\n                               \"high weather forecast usage (median)\",\n                               \"high general risk attitude (median)\",\n                               \"high weather risk attitude (median)\",\n                               \"high accuracy (median)\",\n                               \"high credibility (median)\",\n                               \"Constant\"), \n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE,\n          style = \"qje\")\n\n\n\nLinear regressions: Explanatory analysis of Ambiguity Indices b and a\n\n\n\n\n\n\n\n\n\nb\n\n\na\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n\n\n\n\n\n\nage(35-52)\n\n\n-0.004\n\n\n-0.001\n\n\n0.065*\n\n\n0.050\n\n\n\n\n\n\n(0.021)\n\n\n(0.021)\n\n\n(0.037)\n\n\n(0.036)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage(53-69)\n\n\n-0.047**\n\n\n-0.043*\n\n\n0.149***\n\n\n0.139***\n\n\n\n\n\n\n(0.023)\n\n\n(0.023)\n\n\n(0.038)\n\n\n(0.037)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngender (female)\n\n\n-0.064***\n\n\n-0.055***\n\n\n0.037\n\n\n0.040\n\n\n\n\n\n\n(0.017)\n\n\n(0.017)\n\n\n(0.027)\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh education\n\n\n-0.071***\n\n\n-0.072***\n\n\n0.022\n\n\n0.025\n\n\n\n\n\n\n(0.018)\n\n\n(0.018)\n\n\n(0.028)\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh income\n\n\n0.024\n\n\n0.019\n\n\n0.018\n\n\n0.027\n\n\n\n\n\n\n(0.017)\n\n\n(0.017)\n\n\n(0.030)\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfamily (married or same sex union)\n\n\n-0.019\n\n\n-0.017\n\n\n-0.056*\n\n\n-0.059*\n\n\n\n\n\n\n(0.019)\n\n\n(0.019)\n\n\n(0.032)\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparentship\n\n\n0.020\n\n\n0.016\n\n\n-0.054*\n\n\n-0.052*\n\n\n\n\n\n\n(0.020)\n\n\n(0.020)\n\n\n(0.030)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh temperature (median)\n\n\n\n\n-0.022\n\n\n\n\n-0.074***\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh weather forecast usage (median)\n\n\n\n\n-0.016\n\n\n\n\n-0.008\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh general risk attitude (median)\n\n\n\n\n0.028\n\n\n\n\n-0.010\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh weather risk attitude (median)\n\n\n\n\n0.025\n\n\n\n\n-0.028\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh accuracy (median)\n\n\n\n\n-0.025\n\n\n\n\n-0.010\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n(0.035)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhigh credibility (median)\n\n\n\n\n0.007\n\n\n\n\n-0.046\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.013\n\n\n0.017\n\n\n0.656***\n\n\n0.759***\n\n\n\n\n\n\n(0.023)\n\n\n(0.034)\n\n\n(0.039)\n\n\n(0.053)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN\n\n\n1,361\n\n\n1,361\n\n\n1,361\n\n\n1,361\n\n\n\n\nR2\n\n\n0.028\n\n\n0.036\n\n\n0.015\n\n\n0.024\n\n\n\n\nAdjusted R2\n\n\n0.023\n\n\n0.026\n\n\n0.009\n\n\n0.015\n\n\n\n\nResidual Std. Error\n\n\n0.289\n\n\n0.289\n\n\n0.480\n\n\n0.479\n\n\n\n\nF Statistic\n\n\n5.550***\n\n\n3.835***\n\n\n2.845***\n\n\n2.542***\n\n\n\n\n\n\n\n\nNotes:\n\n\n***Significant at the 1 percent level.\n\n\n\n\n\n\n**Significant at the 5 percent level.\n\n\n\n\n\n\n*Significant at the 10 percent level."
  },
  {
    "objectID": "02-tables.html#table-4",
    "href": "02-tables.html#table-4",
    "title": "2  Tables",
    "section": "3.4 Table 4",
    "text": "3.4 Table 4\n\nols_4_1 &lt;- lm(formula = b ~ surprise + treated + surprise*treated, \n            data = data)\nse_4_1  &lt;- coeftest(x = ols_4_1, \n                    vcov = vcovCL(ols_4_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n\nols_4_2 &lt;- lm(formula = b ~ communication + treated + communication*treated, \n            data = data,\n            subset = (surprise == FALSE))\nse_4_2  &lt;- coeftest(x = ols_4_2, \n                    vcov = vcovCL(ols_4_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n\nols_4_3 &lt;- lm(formula = b ~ communication + treated + communication*treated, \n            data = data,\n            subset = (surprise == TRUE))\nse_4_3  &lt;- coeftest(x = ols_4_3, \n                    vcov = vcovCL(ols_4_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n\nols_4_4 &lt;- lm(formula = b ~ surprise + treated + surprise*treated, \n            data = data,\n            subset = (communication == \"point\"))\nse_4_4  &lt;- coeftest(x = ols_4_4, \n                    vcov = vcovCL(ols_4_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n\nols_4_5 &lt;- lm(formula = b ~ surprise + treated + surprise*treated, \n            data = data,\n            subset = (communication == \"interval\"))\nse_4_5  &lt;- coeftest(x = ols_4_5, \n                    vcov = vcovCL(ols_4_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n\nols_4_6 &lt;- lm(formula = b ~ surprise + treated + surprise*treated, \n            data = data,\n            subset = (communication == \"both\"))\nse_4_6  &lt;- coeftest(x = ols_4_6, \n                    vcov = vcovCL(ols_4_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n\nse_4 &lt;- list(se_4_1[,2], se_4_2[,2], se_4_3[,2], se_4_4[,2], se_4_5[,2], se_4_6[,2])\np_4  &lt;- list(se_4_1[,4], se_4_2[,4], se_4_3[,4], se_4_4[,4], se_4_5[,4], se_4_6[,4])\n\nstargazer(ols_4_1, ols_4_2, ols_4_3, ols_4_4, ols_4_5, ols_4_6, \n          align = TRUE, \n          se = se_4, \n          p = p_4,   \n          title = \"Linear regressions: Treatment effects on ambiguity index b\",\n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on ambiguity index b\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nb\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\nsurprise\n\n\n0.002\n\n\n\n\n\n\n0.012\n\n\n-0.014\n\n\n0.007\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n(0.026)\n\n\n(0.027)\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationboth\n\n\n\n\n-0.038\n\n\n-0.043\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationinterval\n\n\n\n\n-0.017\n\n\n-0.043\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreated\n\n\n-0.020**\n\n\n-0.041***\n\n\n-0.0002\n\n\n-0.041***\n\n\n-0.010\n\n\n-0.008\n\n\n\n\n\n\n(0.008)\n\n\n(0.014)\n\n\n(0.014)\n\n\n(0.014)\n\n\n(0.014)\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurpriseTRUE:treated\n\n\n0.014\n\n\n\n\n\n\n0.041**\n\n\n0.016\n\n\n-0.015\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n(0.020)\n\n\n(0.020)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationboth:treated\n\n\n\n\n0.034\n\n\n-0.023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.021)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationinterval:treated\n\n\n\n\n0.031\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.068***\n\n\n-0.050***\n\n\n-0.037*\n\n\n-0.050***\n\n\n-0.067***\n\n\n-0.087***\n\n\n\n\n\n\n(0.010)\n\n\n(0.017)\n\n\n(0.019)\n\n\n(0.017)\n\n\n(0.019)\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n3,010\n\n\n1,490\n\n\n1,520\n\n\n1,014\n\n\n1,002\n\n\n994\n\n\n\n\nR2\n\n\n0.001\n\n\n0.003\n\n\n0.006\n\n\n0.005\n\n\n0.0003\n\n\n0.001\n\n\n\n\nAdjusted R2\n\n\n-0.0002\n\n\n-0.001\n\n\n0.002\n\n\n0.003\n\n\n-0.003\n\n\n-0.002\n\n\n\n\nResidual Std. Error\n\n\n0.310\n\n\n0.300\n\n\n0.320\n\n\n0.299\n\n\n0.317\n\n\n0.315\n\n\n\n\nF Statistic\n\n\n0.770\n\n\n0.819\n\n\n1.694\n\n\n1.851\n\n\n0.083\n\n\n0.244\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "02-tables.html#table-5",
    "href": "02-tables.html#table-5",
    "title": "2  Tables",
    "section": "3.5 Table 5",
    "text": "3.5 Table 5\n\nols_5_1 &lt;- lm(formula = a ~ surprise + treated + surprise*treated,\n              data = data)\nse_5_1  &lt;- coeftest(x = ols_5_1, \n                    vcov = vcovCL(ols_5_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n\nols_5_2 &lt;- lm(formula = a ~ communication + treated + communication*treated,\n              data = data,\n              subset = (surprise == FALSE))\nse_5_2  &lt;- coeftest(x = ols_5_2, \n                    vcov = vcovCL(ols_5_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n\nols_5_3 &lt;- lm(formula = a ~ communication + treated + communication*treated,\n              data = data,\n              subset = (surprise == TRUE))\nse_5_3  &lt;- coeftest(x = ols_5_3, \n                    vcov = vcovCL(ols_5_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n\nols_5_4 &lt;- lm(formula = a ~ surprise + treated + surprise*treated, \n              data = data,\n              subset = (communication == \"point\"))\nse_5_4  &lt;- coeftest(x = ols_5_4, \n                    vcov = vcovCL(ols_5_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n\nols_5_5 &lt;- lm(formula = a ~ surprise + treated + surprise*treated, \n              data = data,\n              subset = (communication == \"interval\"))\nse_5_5  &lt;- coeftest(x = ols_5_5, \n                    vcov = vcovCL(ols_5_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n\nols_5_6 &lt;- lm(formula = a ~ surprise + treated + surprise*treated, \n              data = data,\n              subset = (communication == \"both\"))\nse_5_6  &lt;- coeftest(x = ols_5_6, \n                    vcov = vcovCL(ols_5_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n\nse_5 &lt;- list(se_5_1[,2], se_5_2[,2], se_5_3[,2], se_5_4[,2], se_5_5[,2], se_5_6[,2])\np_5  &lt;- list(se_5_1[,4], se_5_2[,4], se_5_3[,4], se_5_4[,4], se_5_5[,4], se_5_6[,4])\n\nstargazer(ols_5_1, ols_5_2, ols_5_3, ols_5_4, ols_5_5, ols_5_6, \n          align = TRUE, \n          se = se_5, \n          p = p_5,   \n          title = \"Linear regressions: Treatment effects on ambiguity index a\",\n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on ambiguity index a\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\na\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\nsurprise\n\n\n-0.045*\n\n\n\n\n\n\n0.002\n\n\n-0.046\n\n\n-0.092**\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n(0.044)\n\n\n(0.045)\n\n\n(0.041)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationboth\n\n\n\n\n0.063\n\n\n-0.030\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.043)\n\n\n(0.041)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationinterval\n\n\n\n\n0.023\n\n\n-0.026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.045)\n\n\n(0.044)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntreated\n\n\n-0.007\n\n\n0.023\n\n\n-0.022\n\n\n0.023\n\n\n-0.004\n\n\n-0.041\n\n\n\n\n\n\n(0.020)\n\n\n(0.036)\n\n\n(0.033)\n\n\n(0.036)\n\n\n(0.033)\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurpriseTRUE:treated\n\n\n0.007\n\n\n\n\n\n\n-0.044\n\n\n0.006\n\n\n0.061\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n(0.049)\n\n\n(0.046)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationboth:treated\n\n\n\n\n-0.064\n\n\n0.042\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.049)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationinterval:treated\n\n\n\n\n-0.027\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.049)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.740***\n\n\n0.712***\n\n\n0.714***\n\n\n0.712***\n\n\n0.734***\n\n\n0.775***\n\n\n\n\n\n\n(0.018)\n\n\n(0.031)\n\n\n(0.031)\n\n\n(0.031)\n\n\n(0.033)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n3,010\n\n\n1,490\n\n\n1,520\n\n\n1,014\n\n\n1,002\n\n\n994\n\n\n\n\nR2\n\n\n0.002\n\n\n0.001\n\n\n0.0004\n\n\n0.001\n\n\n0.002\n\n\n0.005\n\n\n\n\nAdjusted R2\n\n\n0.001\n\n\n-0.002\n\n\n-0.003\n\n\n-0.002\n\n\n-0.001\n\n\n0.002\n\n\n\n\nResidual Std. Error\n\n\n0.513\n\n\n0.516\n\n\n0.512\n\n\n0.515\n\n\n0.535\n\n\n0.490\n\n\n\n\nF Statistic\n\n\n1.647\n\n\n0.405\n\n\n0.123\n\n\n0.285\n\n\n0.549\n\n\n1.639\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "02-tables.html#table-6",
    "href": "02-tables.html#table-6",
    "title": "2  Tables",
    "section": "3.6 Table 6",
    "text": "3.6 Table 6\n\nols_6_1 &lt;- lm(formula = ed ~ surprise, \n            data = data,\n            subset = (stage == 2))\nse_6_1  &lt;- coeftest(ols_6_1, vcov = vcovHC(ols_6_1, type = \"HC1\"))\n\nols_6_2 &lt;- lm(formula = ed ~ communication, \n            data = data,\n            subset = (stage == 2 & surprise == FALSE))\nse_6_2  &lt;- coeftest(ols_6_2, vcov = vcovHC(ols_6_2, type = \"HC1\"))\n\nols_6_3 &lt;- lm(formula = ed ~ communication, \n            data = data,\n            subset = (stage == 2 & surprise == TRUE))\nse_6_3  &lt;- coeftest(ols_6_3, vcov = vcovHC(ols_6_3, type = \"HC1\"))\n\nols_6_4 &lt;- lm(formula = ed ~ surprise, \n            data = data,\n            subset = (stage == 2 & communication == \"point\"))\nse_6_4  &lt;- coeftest(ols_6_4, vcov = vcovHC(ols_6_4, type = \"HC1\"))\n\nols_6_5 &lt;- lm(formula = ed ~ surprise, \n            data = data,\n            subset = (stage == 2 & communication == \"interval\"))\nse_6_5  &lt;- coeftest(ols_6_5, vcov = vcovHC(ols_6_5, type = \"HC1\"))\n\nols_6_6 &lt;- lm(formula = ed ~ surprise, \n            data = data,\n            subset = (stage == 2 & communication == \"both\"))\nse_6_6  &lt;- coeftest(ols_6_6, vcov = vcovHC(ols_6_6, type = \"HC1\"))\n\nse_6 &lt;- list(se_6_1[,2], se_6_2[,2], se_6_3[,2], se_6_4[,2], se_6_5[,2], se_6_6[,2])\np_6  &lt;- list(se_6_1[,4], se_6_2[,4], se_6_3[,4], se_6_4[,4], se_6_5[,4], se_6_6[,4])\n\nstargazer(ols_6_1, ols_6_2, ols_6_3, ols_6_4, ols_6_5, ols_6_6, \n          align = TRUE, \n          se = se_6,\n          p = p_6,   \n          title = \"Linear regressions: Treatment effects on Euclidian distance between vector of matching probabilities in part 1 vs. part 2\",\n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on Euclidian distance between vector of matching probabilities in part 1 vs. part 2\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ned\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\nsurprise\n\n\n6.824***\n\n\n\n\n\n\n10.120***\n\n\n2.423\n\n\n8.023**\n\n\n\n\n\n\n(1.775)\n\n\n\n\n\n\n(3.029)\n\n\n(3.033)\n\n\n(3.158)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationboth\n\n\n\n\n1.195\n\n\n-0.902\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.991)\n\n\n(3.194)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommunicationinterval\n\n\n\n\n0.701\n\n\n-6.996**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.933)\n\n\n(3.126)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n44.941***\n\n\n44.316***\n\n\n54.436***\n\n\n44.316***\n\n\n45.017***\n\n\n45.511***\n\n\n\n\n\n\n(1.224)\n\n\n(2.001)\n\n\n(2.274)\n\n\n(2.001)\n\n\n(2.144)\n\n\n(2.223)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,505\n\n\n745\n\n\n760\n\n\n507\n\n\n501\n\n\n497\n\n\n\n\nR2\n\n\n0.010\n\n\n0.0002\n\n\n0.008\n\n\n0.022\n\n\n0.001\n\n\n0.013\n\n\n\n\nAdjusted R2\n\n\n0.009\n\n\n-0.002\n\n\n0.005\n\n\n0.020\n\n\n-0.001\n\n\n0.011\n\n\n\n\nResidual Std. Error\n\n\n34.441\n\n\n33.445\n\n\n35.337\n\n\n34.076\n\n\n33.956\n\n\n35.205\n\n\n\n\nF Statistic\n\n\n14.768***\n\n\n0.081\n\n\n2.966*\n\n\n11.180***\n\n\n0.637\n\n\n6.453**\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "03-figures.html#install-packages",
    "href": "03-figures.html#install-packages",
    "title": "3  Figures",
    "section": "3.1 Install Packages",
    "text": "3.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n    library(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"lubridate\", \"knitr\", \"glue\",\n          \"sandwich\", \"lmtest\",\n          \"ggplot2\", \"ggpubr\", \"rstatix\", \"patchwork\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2023-09-25\")"
  },
  {
    "objectID": "03-figures.html#read-data",
    "href": "03-figures.html#read-data",
    "title": "3  Figures",
    "section": "3.2 Read Data",
    "text": "3.2 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\ndata[, communication := as.factor(communication)]\ndata[, communication := factor(communication, levels = c(\"point\", \"interval\", \"both\"))]\ndata[, stage := as.factor(stage)]\ndata[, stage := factor(stage, levels = c(\"1\", \"2\"))]"
  },
  {
    "objectID": "03-figures.html#figure-1",
    "href": "03-figures.html#figure-1",
    "title": "3  Figures",
    "section": "3.3 Figure 1",
    "text": "3.3 Figure 1\nTo create Figure 3.1 (and fig-2), we create a wrapper function that we can call several times. As all the other figures presented in this document, Figure 3.1 consists of three panels, top, left, and right that are relatively similar. We thus, save both space and sources of error by creating a wrapper function plot_bars() that creates bar plots and annotates them with test statistics.\n\nplot_bars &lt;- function(response = \"b\", surprise_sub = NA, limits = ylim(-1.02, 1.02)){\n  \n  if(response == \"b\"){\n      y_1 = 0.6\n      y_2 = 0.4\n    } else {\n      y_1 = 1.4\n      y_2 = 1\n    }\n  \n  if(!is.na(surprise_sub)){\n    # Plot bottom panels\n    tmp &lt;- data[surprise == surprise_sub]\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    if(surprise_sub){\n      title &lt;- \"Surprising Condition\"\n    } else {\n      title &lt;- \"Confirming Condition\"\n    }\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(communication) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ communication) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    plot_bottom &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(communication),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"communication\") +\n      labs(title = title,\n           x = \"Communication\",\n           y = glue(\"Ambiguity index {response} (Baillon)\"))\n    \n    rm(tmp)\n    \n    plot_bottom\n  } else {\n    # Plot the top panel\n    tmp &lt;- data\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    title &lt;- \"Both Conditions\"\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(surprise) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ surprise) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    \n    plot_top &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(surprise),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"surprise\") +\n      labs(title = title,\n           x = \" Surprising Condition\",\n           y = glue(\"Ambiguity index {response} (Baillon)\"))\n    \n    rm(tmp)\n    \n    plot_top\n  }\n}\n\n\ntop   &lt;- plot_bars(response = \"b\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"b\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"b\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 3.1: Means of ambiguity index b separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "03-figures.html#figure-2",
    "href": "03-figures.html#figure-2",
    "title": "3  Figures",
    "section": "3.4 Figure 2",
    "text": "3.4 Figure 2\nNext, we use the wrapper function again but visualize another outcome using the response == a argument.\n\ntop   &lt;- plot_bars(response = \"a\", limits = ylim(-2.01, 4.01), surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"a\", limits = ylim(-2.01, 4.01), surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"a\", limits = ylim(-2.01, 4.01), surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 3.2: Means of ambiguity index a separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "03-figures.html#figure-3",
    "href": "03-figures.html#figure-3",
    "title": "3  Figures",
    "section": "3.5 Figure 3",
    "text": "3.5 Figure 3\nFigure 3.3 also presents three panels. In contrast to Figure 3.1 and Figure 3.2, these panels visualize confidence intervals of our estimator of interest: the interaction of stage and surprise (top panel) as well as the interaction between stage and communication in the lower two panels.\nThe corresponding data stems from many OLS regressions and are computed in for-loops. Even though the code differs slightly, it is very repetitive between the three panels, which is why we only explain the top panel\n\n3.5.1 Top Panel\nBefore calculating the data based on OLS regressions, we specify three different models: none represents only treatment variables, demographics extends the former by adding demographic variables, and all extends the former two by also adding all remaining covariates.\n\nnone &lt;- c(\"surprise\", \"treated\", \"surprise*treated\")\n\ndemographics &lt;- c(none, \"age_35_52\",\"age_53_plus\",\"female\", \"high_education\", \"high_income\", \"married\", \"parentship\")\n\nall &lt;- c(demographics, \"high_temperature\",\"high_usage\",\"high_general_risk\",\"high_weather_risk\",\"high_accuracy\",\"high_credibility\")\n\nNext, we run a nested loop that iterates through all three models and within these models through both ambiguity indices a and b. From these ols regressions, we compute clustered standard errors using the {{sandwich}} and {{lmtest}} package. The resuling data is stored in a temporary data.table that is appended to an initially empty data.table called ci_top.\n\nci_top &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in c(\"a\", \"b\")){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data)\n    \n    tmp &lt;- coefci(x = ols,\n                  parm = \"surpriseTRUE:treatedTRUE\",\n                  vcov = vcovCL(x = ols, \n                                cluster = data$participant.label, \n                                type = \"HC1\"),\n                  level = 0.95) %&gt;% \n      data.table(model = RHS, outcome = LHS)\n    tmp[, center := (`2.5 %` + `97.5 %`)/2]\n    \n    ci_top &lt;- rbind(ci_top, tmp)\n  }\n}\n\nThe result looks as follows. The data.table provides a column for the 2.5% and 97.5% confidence interval, the center of the two, as well as the ols specification as presented in model and outcome.\n\nci_top %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n-0.0461365\n0.0608289\nnone\na\n0.0073462\n\n\n-0.0085981\n0.0374200\nnone\nb\n0.0144110\n\n\n-0.0370710\n0.0733050\ndemographics\na\n0.0181170\n\n\n-0.0071204\n0.0418846\ndemographics\nb\n0.0173821\n\n\n-0.0371322\n0.0733663\nall\na\n0.0181170\n\n\n-0.0071476\n0.0419118\nall\nb\n0.0173821\n\n\n\n\n\nFinally, we plot this data set (ci_top) using the {{ggplot2}} package. The resulting object is stored as top and will be assembled together with the other two panels.\n\ntop &lt;- ggplot(data = ci_top,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_top,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(#title = \"(a) Effect of contradiction (relative to confirmation)\",\n       y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\")\n\n\n\n3.5.2 Left Panel\n\nnone &lt;- c(\"communication\", \"treated\", \"communication*treated\")\n\ndemographics &lt;- c(none, \"age_35_52\",\"age_53_plus\",\"female\", \"high_education\", \"high_income\", \"married\", \"parentship\")\n\nall &lt;- c(demographics, \"high_temperature\",\"high_usage\",\"high_general_risk\",\"high_weather_risk\",\"high_accuracy\",\"high_credibility\")\n\n\nci_left &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in c(\"a\", \"b\")){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data,\n              subset = (surprise == FALSE))\n    for(communication in c(\"interval\", \"both\")){\n      tmp &lt;- coefci(x = ols,\n                    parm = paste0(\"communication\", communication, \":treatedTRUE\"),\n                    vcov = vcovCL(x = ols, \n                                  cluster = data[surprise == FALSE,\n                                                 participant.label], \n                                  type = \"HC1\"),\n                    level = 0.95) %&gt;% \n        data.table(model = RHS, outcome = paste0(LHS, \" (\", communication, \")\"))\n      tmp[, center := (`2.5 %` + `97.5 %`)/2]\n      \n      ci_left &lt;- rbind(ci_left, tmp)\n    }\n  }\n}\n\n\nci_left %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n-0.1231424\n0.0699195\nnone\na (interval)\n-0.0266115\n\n\n-0.1603397\n0.0317751\nnone\na (both)\n-0.0642823\n\n\n-0.0085202\n0.0705807\nnone\nb (interval)\n0.0310303\n\n\n-0.0069006\n0.0744238\nnone\nb (both)\n0.0337616\n\n\n-0.1032781\n0.0924975\ndemographics\na (interval)\n-0.0053903\n\n\n-0.1519774\n0.0393496\ndemographics\na (both)\n-0.0563139\n\n\n-0.0106052\n0.0750051\ndemographics\nb (interval)\n0.0321999\n\n\n\n\n\n\nleft &lt;- ggplot(data = ci_left,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_left,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(#title = \"(b) Effect of information treatments (both, interval) relative to best guess, confirmation treatments\",\n       y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\")\n\n\n\n3.5.3 Right Panel\n\nci_right &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in c(\"a\", \"b\")){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data,\n              subset = (surprise == TRUE))\n    for(communication in c(\"interval\", \"both\")){\n      tmp &lt;- coefci(x = ols,\n                    parm = paste0(\"communication\", communication, \":treatedTRUE\"),\n                    vcov = vcovCL(x = ols, \n                                  cluster = data[surprise == TRUE,\n                                                 participant.label], \n                                  type = \"HC1\"),\n                    level = 0.95) %&gt;% \n        data.table(model = RHS, outcome = paste0(LHS, \" (\", communication, \")\"))\n      tmp[, center := (`2.5 %` + `97.5 %`)/2]\n      \n      ci_right &lt;- rbind(ci_right, tmp)\n    }\n  }\n}\n\n\nci_right %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n-0.0664967\n0.1147544\nnone\na (interval)\n0.0241288\n\n\n-0.0495534\n0.1325661\nnone\na (both)\n0.0415063\n\n\n-0.0339037\n0.0457592\nnone\nb (interval)\n0.0059278\n\n\n-0.0619626\n0.0165198\nnone\nb (both)\n-0.0227214\n\n\n-0.0798350\n0.1115715\ndemographics\na (interval)\n0.0158682\n\n\n-0.0675663\n0.1267932\ndemographics\na (both)\n0.0296134\n\n\n-0.0490060\n0.0352795\ndemographics\nb (interval)\n-0.0068632\n\n\n\n\n\n\nright &lt;- ggplot(data = ci_right,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_right,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(#title = \"(c) Effect of information treatments (both, interval) relative to best guess, contradiction treatments\",\n       y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\") +\n  scale_y_discrete(position = \"right\")\n\n\n\n3.5.4 Assemble Top, Left and Right Panels\nAs before, we use the {{patchwork}} package to assmble the plot objects.\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 3.3: Treatment effects of regression equation (1) with dependent variables b and a. Estimators with 95% confidence intervals. The underlying standard errors (“HC1”) are clustered at the individual level and estimated with the R package sandwich (Zeileis, 2004; Zeileis et al., 2020)."
  },
  {
    "objectID": "03-figures.html#figure-4",
    "href": "03-figures.html#figure-4",
    "title": "3  Figures",
    "section": "3.6 Figure 4",
    "text": "3.6 Figure 4\nThe process of producing Figure 3.4 is very similar to the process of Figure 3.3. The only difference is that we do not loop through the outcomes a and b but the events’ matching probabilities (E1, E2, ..., E23).\nTo loop through these variables, we use a regex (E\\\\d) to create a vector called events.\n\nevents &lt;- names(data) %&gt;% str_subset(pattern = \"E\\\\d\")\n\nBecause the process is, from now on, so similar to the process of Figure 3.3, we do not comment it any further here.\n\n3.6.1 Top Panel\n\nnone &lt;- c(\"surprise\", \"treated\", \"surprise*treated\")\n\ndemographics &lt;- c(none, \"age_35_52\",\"age_53_plus\",\"female\", \"high_education\", \"high_income\", \"married\", \"parentship\")\n\nall &lt;- c(demographics, \"high_temperature\",\"high_usage\",\"high_general_risk\",\"high_weather_risk\",\"high_accuracy\",\"high_credibility\")\n\n\nci_top &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in events){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data)\n    \n    tmp &lt;- coefci(x = ols,\n                  parm = \"surpriseTRUE:treatedTRUE\",\n                  vcov = vcovCL(x = ols, \n                                cluster = data$participant.label, \n                                type = \"HC1\"),\n                  level = 0.95) %&gt;% data.table(model = RHS, outcome = LHS)\n    tmp[, center := (`2.5 %` + `97.5 %`)/2]\n    \n    ci_top &lt;- rbind(ci_top, tmp)\n  }\n}\n\n\nci_top %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n4.983983\n10.142448\nnone\nE1\n7.563215\n\n\n1.600247\n6.299091\nnone\nE12\n3.949669\n\n\n1.327104\n6.115620\nnone\nE13\n3.721362\n\n\n-7.842483\n-3.429947\nnone\nE2\n-5.636215\n\n\n-12.800137\n-7.599836\nnone\nE23\n-10.199987\n\n\n-6.107878\n-1.334793\nnone\nE3\n-3.721335\n\n\n4.421240\n9.844463\ndemographics\nE1\n7.132852\n\n\n\n\n\n\ntop &lt;- ggplot(data = ci_top,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_top,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\")\n\n\n\n3.6.2 Left Panel\n\nnone &lt;- c(\"communication\", \"treated\", \"communication*treated\")\n\ndemographics &lt;- c(none, \"age_35_52\",\"age_53_plus\",\"female\", \"high_education\", \"high_income\", \"married\", \"parentship\")\n\nall &lt;- c(demographics, \"high_temperature\",\"high_usage\",\"high_general_risk\",\"high_weather_risk\",\"high_accuracy\",\"high_credibility\")\n\n\nci_left &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in events){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data,\n              subset = (surprise == FALSE))\n    for(communication in c(\"interval\", \"both\")){\n      tmp &lt;- coefci(x = ols,\n                    parm = paste0(\"communication\", communication, \":treatedTRUE\"),\n                    vcov = vcovCL(x = ols, \n                                  cluster = data[surprise == FALSE,\n                                                 participant.label], \n                                  type = \"HC1\"),\n                    level = 0.95) %&gt;% \n        data.table(model = RHS, outcome = paste0(LHS, \" (\", communication, \")\"))\n      tmp[, center := (`2.5 %` + `97.5 %`)/2]\n      \n      ci_left &lt;- rbind(ci_left, tmp)\n    }\n  }\n}\n\n\nci_left %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n-6.746653\n1.5693594\nnone\nE1 (interval)\n-2.5886468\n\n\n-7.472010\n0.5541086\nnone\nE1 (both)\n-3.4589505\n\n\n-7.466795\n0.4839339\nnone\nE12 (interval)\n-3.4914306\n\n\n-4.297893\n3.4859217\nnone\nE12 (both)\n-0.4059856\n\n\n-2.758720\n5.5611888\nnone\nE13 (interval)\n1.4012346\n\n\n-6.134510\n2.0764806\nnone\nE13 (both)\n-2.0290148\n\n\n-4.899051\n2.4400333\nnone\nE2 (interval)\n-1.2295086\n\n\n\n\n\n\nleft &lt;- ggplot(data = ci_left,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_left,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\")\n\n\n\n3.6.3 Right Panel\n\nci_right &lt;- data.table()\nfor(RHS in c(\"none\", \"demographics\", \"all\")){\n  for(LHS in events){\n    ols &lt;- lm(formula = reformulate(termlabels = get(RHS), \n                                    response = LHS),\n              data = data,\n              subset = (surprise == TRUE))\n    for(communication in c(\"interval\", \"both\")){\n      tmp &lt;- coefci(x = ols,\n                    parm = paste0(\"communication\", communication, \":treatedTRUE\"),\n                    vcov = vcovCL(x = ols, \n                                  cluster = data[surprise == TRUE,\n                                                 participant.label], \n                                  type = \"HC1\"),\n                    level = 0.95) %&gt;% \n        data.table(model = RHS, outcome = paste0(LHS, \" (\", communication, \")\"))\n      tmp[, center := (`2.5 %` + `97.5 %`)/2]\n      \n      ci_right &lt;- rbind(ci_right, tmp)\n    }\n  }\n}\n\n\nci_right %&gt;% head(n = 7) %&gt;% kable()\n\n\n\n\n2.5 %\n97.5 %\nmodel\noutcome\ncenter\n\n\n\n\n-9.6135941\n-0.0515961\nnone\nE1 (interval)\n-4.8325951\n\n\n-2.8115517\n7.0630438\nnone\nE1 (both)\n2.1257460\n\n\n-4.0358433\n4.3361386\nnone\nE12 (interval)\n0.1501477\n\n\n-0.4741903\n8.1055554\nnone\nE12 (both)\n3.8156825\n\n\n-8.3619000\n-0.3107652\nnone\nE13 (interval)\n-4.3363326\n\n\n-6.0444150\n2.5918118\nnone\nE13 (both)\n-1.7263016\n\n\n-1.4998061\n6.0782483\nnone\nE2 (interval)\n2.2892211\n\n\n\n\n\n\nright &lt;- ggplot(data = ci_right,\n       mapping = aes(y = outcome)) +\n  geom_pointrange(mapping = aes(x = center,\n                                y = outcome,\n                                xmin = `2.5 %`,\n                                xmax = `97.5 %`,\n                                shape = factor(model)),\n                  data = ci_right,\n                  position = position_dodge(width = 0.4),\n                  fatten=5,\n                  alpha=.8) +\n  geom_vline(xintercept = 0, \n             color = \"red\", \n             alpha = 0.66, \n             show.legend = FALSE) +\n  theme_bw() +\n  labs(y = \"Ambiguity Index\", \n       x = \"Estimate\",\n       shape=\"Control variables\") +\n  scale_y_discrete(position = \"right\")\n\n\n\n3.6.4 Assemble Top, Left and Right Panels\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 3.4: Treatment effects of regression equation (1) with matching probabilities for all events as depen- dent variables. Estimators with 95% confidence intervals. The underlying standard errors (“HC1”) are clustered at the individual level and estimated with the R package sandwich (Zeileis, 2004; Zeileis et al., 2020)."
  },
  {
    "objectID": "X-references.html",
    "href": "X-references.html",
    "title": "References",
    "section": "",
    "text": "Anantanasuwong, Kanin, Roy Kouwenberg, Olivia S Mitchell, and Kim\nPeijnenberg. 2019. “Ambiguity Attitudes about Investments:\nEvidence from the Field.” Working Paper 25561. Working Paper\nSeries. National Bureau of Economic Research. https://doi.org/10.3386/w25561.\n\n\nBaillon, Aurélien, Zhenxing Huang, Asli Selim, and Peter P. Wakker.\n2018. “Measuring Ambiguity Attitudes for All (Natural)\nEvents.” Econometrica 86 (5): 1839–58. https://doi.org/10.3982/ECTA14370.\n\n\nChen, Daniel L., Martin Schonger, and Chris Wickens. 2016.\n“oTree-an Open-Source Platform for Laboratory, Online, and Field\nExperiments.” Journal of Behavioral and Experimental\nFinance 9: 88–97. https://doi.org/10.1016/j.jbef.2015.12.001."
  },
  {
    "objectID": "X-session-info.html",
    "href": "X-session-info.html",
    "title": "Appendix A — Session Info",
    "section": "",
    "text": "sessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.3.1       htmltools_0.5.7   rstudioapi_0.15.0 rmarkdown_2.25   \n [9] knitr_1.44        jsonlite_1.8.7    xfun_0.40         digest_0.6.33    \n[13] rlang_1.1.1       evaluate_0.21"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ambiguity attitudes and surprises",
    "section": "",
    "text": "Preface\nThis document explains and shows how to reproduce the figures and tables presented in our paper using a literate programming approach (Knuth 1984).\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "A-online-appendix.html#setup",
    "href": "A-online-appendix.html#setup",
    "title": "7  Online Appendix A",
    "section": "7.1 Setup",
    "text": "7.1 Setup\n\n7.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n    library(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2023-09-25\")\n\n\n\n7.1.2 Read Data\n\ndata      &lt;- readRDS(file=\"../data/processed/full.Rda\")\ntimeSpent &lt;- data.table::fread(file = \"../data/raw/PageTimes-2021-09-15.csv\")\nraw       &lt;- data.table::fread(file=\"../data/raw/all_apps_wide_2021-09-15.csv\")\n\n\n\n7.1.3 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)"
  },
  {
    "objectID": "A-online-appendix.html#figure-oa1",
    "href": "A-online-appendix.html#figure-oa1",
    "title": "7  Online Appendix A",
    "section": "7.2 Figure OA1",
    "text": "7.2 Figure OA1\n\ntimeSpent[,\n          lag := shift(epoch_time_completed, fill = NA, type = \"lag\"),\n          by = c(\"session_code\", \"participant_code\")]\ntimeSpent[,\n          duration := epoch_time_completed - lag,\n          by = c(\"session_code\", \"participant_code\")]\ntimeSpent[,\n          completion := epoch_time_completed %&gt;% max() - epoch_time_completed %&gt;% min(),\n          by = c(\"session_code\", \"participant_code\")]\n\nduration &lt;- timeSpent[participant_code %in% data$participant.code,\n                      .(\n                        session_code,\n                        participant_code,\n                        app_name,\n                        page_name,\n                        page_index,\n                        page_submission = epoch_time_completed,\n                        time_spent = duration,\n                        completion_time = completion\n                      )]\n\n\nN &lt;- duration[, participant_code %&gt;% unique() %&gt;% length()]\n\ntmp &lt;- duration[app_name == \"Baillon\" & page_name == \"Baillon_Decision\",\n                 .(time_spent = time_spent %&gt;% sum()),\n                 by = c(\"session_code\", \"participant_code\", \"page_index\", \"page_name\")]\n\ntmp[, round := page_index-2, by = c(\"participant_code\")]\n\n# remove outliers\nplotDT &lt;- tmp[,\n               .SD[time_spent &lt; quantile(time_spent, probs = 0.99)],\n               by = page_index]\n\nggplot(data = summarySE(data = plotDT,\n                        measurevar = \"time_spent\",\n                        groupvars=c(\"round\"),\n                        na.rm = FALSE,\n                        conf.interval = 0.95,\n                        .drop = TRUE),\n       mapping = aes(x = round, y = time_spent)) +\n  geom_hline(yintercept = 0) +\n  layout +\n  theme(legend.position=\"bottom\") +\n  geom_line(show.legend=FALSE, color = colors[2], lty=2) +\n  geom_errorbar(aes(ymin=time_spent-ci, ymax=time_spent+ci), width=.25, alpha = 0.5, color = colors[3]) +\n  geom_point(color = colors[2]) +\n  scale_x_continuous(name=\"\", breaks = 1:12) +\n  scale_y_continuous(limits = c(0, NA), expand = c(0, 0),\n                     breaks = c(0,\n                                plotDT[round == 1, time_spent %&gt;% mean() %&gt;% round(digits=0)],\n                                plotDT[round == 2, time_spent %&gt;% mean() %&gt;% round(digits=0)],\n                                plotDT[round == 7, time_spent %&gt;% mean() %&gt;% round(digits=0)],\n                                plotDT[round == 12, time_spent %&gt;% mean() %&gt;% round(digits=0)])) +\n  labs(y = \"Response Time in Seconds\", caption = \"Bars indicate 95% confidence intervals.\n\\nOutliers (identified by 99.0 quantile) removed.\")\n\nrm(list = c(\"tmp\", \"timeSpent\", \"duration\", \"plotDT\", \"pkgs\"))\n\n\n\n\nFigure 7.1: Average response time of the 12 ambiguity tasks of the full sample (1505 observations; outliers removed as described in the figure)."
  },
  {
    "objectID": "A-online-appendix.html#figure-oa.2",
    "href": "A-online-appendix.html#figure-oa.2",
    "title": "7  Online Appendix A",
    "section": "7.3 Figure OA.2",
    "text": "7.3 Figure OA.2\n\nggplot(data = raw[nchar(participant.label) == 32 & session.is_demo == 0 & participant._index_in_pages &lt; 20],\n       aes(x=participant._index_in_pages)) + \n  geom_hline(yintercept = 0) +\n  geom_histogram(binwidth = 1, \n                 fill = colors[2])  +\n  scale_y_continuous(limits = c(0, NA), expand = c(0, 0)) +\n  # scale_y_log10(breaks=c(0, 1, 2, 3, 4, 5, 10, 100), expand = c(0, NA)) +\n  layout +\n  labs(x = \"Pages\") +\n  scale_x_continuous(breaks = c(2),\n                     labels = c(\"Instructions\")) +\n  labs(y = \"Count\", x = \"Pages\")\n\n\n\n\nFigure 7.2: Dropout participants of the experiment by page number.\n\n\n\n\n\nraw[Intro.1.player.location == \"Ilomantsi\", \n    conditions := paste0(\"contrad.-\",\n                         str_replace_all(string = Intro.1.player.treatment, \n                                         pattern = \"_\", \n                                         replacement = \" \"))]\n\nraw[Intro.1.player.location == \"Weiskirchen\", \n    conditions := paste0(\"conf.-\",\n                         str_replace_all(string = Intro.1.player.treatment, \n                                         pattern = \"_\", \n                                         replacement = \" \"))]\n\nggplot(raw[participant._index_in_pages &gt; 8 & nchar(participant.label) == 32 & session.is_demo == 0 & participant._index_in_pages &lt; 20],\n       aes(x  = conditions)) + \n  geom_hline(yintercept = 0) +\n  geom_bar(fill = colors[2])  +\n  scale_y_continuous(limits = c(0, NA), expand = c(0, NA)) +\n  layout +\n  labs(x = \"Treatments\", y = \"Count\") \n\n\n\n\nFigure 7.3: Dropout participants by treatment after introduction of the treatment."
  },
  {
    "objectID": "B-online-appendix.html#setup",
    "href": "B-online-appendix.html#setup",
    "title": "9  Online Appendix B",
    "section": "9.1 Setup",
    "text": "9.1 Setup\n\n9.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"lubridate\", \"knitr\", \"glue\",\n          \"sandwich\", \"lmtest\",\n          \"ggplot2\", \"ggpubr\", \"rstatix\", \"patchwork\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n9.1.2 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\n\n9.1.3 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)\n\n\n\n9.1.4 Helper Function\n\nplot_bars &lt;- function(response = \"b\", surprise_sub = NA, limits = ylim(-0.1, 100.1)){\n  \n  if(response == \"b\"){\n      y_1 = 75\n      y_2 = 55\n    } else {\n      y_1 = 75\n      y_2 = 60\n    }\n  \n  if(!is.na(surprise_sub)){\n    # Plot bottom panels\n    tmp &lt;- data[surprise == surprise_sub]\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    if(surprise_sub){\n      title &lt;- \"Surprising Condition\"\n    } else {\n      title &lt;- \"Confirming Condition\"\n    }\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(communication) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ communication) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    plot_bottom &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(communication),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"communication\") +\n      labs(title = \"\",\n           x = \" Surprising Condition\",\n           y = glue(\" {response}\"))\n    \n    rm(tmp)\n    \n    plot_bottom\n  } else {\n    # Plot the top panel\n    tmp &lt;- data\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    title &lt;- \"Both Conditions\"\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(surprise) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ surprise) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    \n    plot_top &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(surprise),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"surprise\") +\n      labs(title = \"\",\n           x = \" Surprising Condition\",\n           y = glue(\" {response}\"))\n    \n    rm(tmp)\n    \n    plot_top\n  }\n}"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.1",
    "href": "B-online-appendix.html#figure-ob.1",
    "title": "9  Online Appendix B",
    "section": "9.2 Figure OB.1",
    "text": "9.2 Figure OB.1\nTo create Figure 9.1 (and the other figures), we use the wrapper function defined above. We’ll call several times in what follows. As all the other figures presented in this document, Figure 9.1 consists of three panels, top, left, and right that are relatively similar. We thus, save both space and sources of error by creating a wrapper function plot_bars() that creates bar plots and annotates them with test statistics.\n\ntop   &lt;- plot_bars(response = \"E1\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E1\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E1\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.1: Means of the matching probabilities for event E1 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.2",
    "href": "B-online-appendix.html#figure-ob.2",
    "title": "9  Online Appendix B",
    "section": "9.3 Figure OB.2",
    "text": "9.3 Figure OB.2\nNext, we use the wrapper function again but visualize another outcome using the response == E2 argument.\n\ntop   &lt;- plot_bars(response = \"E2\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E2\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E2\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.2: Means of the matching probabilities for event E2 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.3",
    "href": "B-online-appendix.html#figure-ob.3",
    "title": "9  Online Appendix B",
    "section": "9.4 Figure OB.3",
    "text": "9.4 Figure OB.3\nNext, we use the wrapper function again but visualize another outcome using the response == E3 argument.\n\ntop   &lt;- plot_bars(response = \"E3\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E3\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E3\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.3: Means of the matching probabilities for event E3 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.4",
    "href": "B-online-appendix.html#figure-ob.4",
    "title": "9  Online Appendix B",
    "section": "9.5 Figure OB.4",
    "text": "9.5 Figure OB.4\nNext, we use the wrapper function again but visualize another outcome using the response == E12 argument.\n\ntop   &lt;- plot_bars(response = \"E12\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E12\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E12\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.4: Means of the matching probabilities for event E12 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.5",
    "href": "B-online-appendix.html#figure-ob.5",
    "title": "9  Online Appendix B",
    "section": "9.6 Figure OB.5",
    "text": "9.6 Figure OB.5\nNext, we use the wrapper function again but visualize another outcome using the response == E13 argument.\n\ntop   &lt;- plot_bars(response = \"E13\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E13\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E13\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.5: Means of the matching probabilities for event E13 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "B-online-appendix.html#figure-ob.6",
    "href": "B-online-appendix.html#figure-ob.6",
    "title": "9  Online Appendix B",
    "section": "9.7 Figure OB.6",
    "text": "9.7 Figure OB.6\nNext, we use the wrapper function again but visualize another outcome using the response == E23 argument.\n\ntop   &lt;- plot_bars(response = \"E23\", surprise_sub = NA)\nleft  &lt;- plot_bars(response = \"E23\", surprise_sub = FALSE)\nright &lt;- plot_bars(response = \"E23\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 9.6: Means of the matching probabilities for event E23 separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: ∗p&lt;0.10, ∗∗p&lt;0.05, ∗∗∗p&lt;0.01, ns: not significant"
  },
  {
    "objectID": "C-online-appendix.html#setup",
    "href": "C-online-appendix.html#setup",
    "title": "10  Online Appendix C",
    "section": "10.1 Setup",
    "text": "10.1 Setup\n\n10.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\", \"patchwork\",\n          \"rstatix\", \"ggpubr\", \"glue\", \"lubridate\", \"plyr\", \n          \"lmtest\", \"sandwich\", \"stargazer\" # packages for regression tables\n          )\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n10.1.2 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\n\n10.1.3 Manipulate Data\n[Shall we add this code chunk to the pre-processing?]\n\ndata[, communication := as.factor(communication)]\ndata[, communication := factor(communication, levels = c(\"point\", \"both\",\"interval\"))]\ndata[, stage := as.factor(stage)]\ndata[, stage := factor(stage, levels = c(\"1\", \"2\"))]\n\n\ncols &lt;- str_subset(string = names(data), pattern = \"E\\\\d+\")\ndata[, \n     str_replace_all(string = cols, pattern = \"^E\", replacement = \"m\") := lapply(.SD, function(x) x / 100), \n     .SDcols = cols] \n\ndata[, p1 := 0.5 + (m1 - m23)/ (6*(mc-ms))]\ndata[, p2 := 0.5 + (m2 - m13)/ (6*(mc-ms))]\ndata[, p3 := 0.5 + (m3 - m12)/ (6*(mc-ms))]\n\n\nwide_data &lt;- data.table::dcast(data, \n                                participant.label + surprise + communication ~ stage, \n                                value.var = c(\"E1\", \"E2\", \"E3\", \"E12\", \"E23\",\"E13\", \"b\", \"a\"))\n\nsetorder(wide_data, surprise, communication, participant.label)\n\n\n\n10.1.4 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)\n\n\n\n10.1.5 Helper Function\nTo create Figure 10.1 (and the other figures), we create a wrapper function that we can call several times. Figures such as Figure 10.1 consist of eight panels, that are relatively similar. We thus, save both space and sources of error by creating a wrapper function plot_scatter() that creates scatter plots. To annotate and scale these plots, we also create a wrapper function for plot_scatter() called plot_scatter_with_defaults(). The latter function is called in the script below and contains some hard-coded defaults that determine annotations and the scales, i.e., where the annotations are placed.\n\nplot_scatter &lt;- function(outcome.y = \"b_2\", \n                         outcome.x = \"b_1\", \n                         DT = wide_data[surprise == FALSE & communication == \"both\"], \n                         breaks = seq(from = -1, to = 1, by = 0.5), \n                         limits = c(-1, 1), \n                         # manual annotation positions:\n                         x1 = 0.9,\n                         x2 = 0.3,\n                         x3 = -0.6,\n                         x4 = 0.6, \n                         y1 = - 0.115,\n                         y2 = 1.05,\n                         y3 = 0.7,\n                         y4 = -0.7){\n  \n  \n  # Percentage Annotation\n  p1 &lt;- scales::percent(x = sum(DT[,..outcome.y] &gt; DT[,..outcome.x], na.rm = TRUE) / DT[, .N], \n                        accuracy = 1)\n  p2 &lt;- scales::percent(x = sum(DT[,..outcome.y] &lt; DT[,..outcome.x], na.rm = TRUE) / DT[, .N], \n                        accuracy = 1)\n  \n  # Spearman Correlation for Subtitle\n  ro.value &lt;- round(x = cor(DT[,..outcome.x], \n                            DT[,..outcome.y], \n                            method = c(\"spearman\")),\n                    digits = 2)\n  \n  \n  # Plot\n  plot &lt;- ggplot(data = DT,\n                 mapping = aes(x = get(outcome.x),\n                               y = get(outcome.y))) +\n    geom_count(shape = 1, show.legend = FALSE) +\n    \n    # add axes and diagonal\n    geom_vline(xintercept = 0) +\n    geom_hline(yintercept = 0) +\n    geom_abline(intercept = 0, slope = 1, linewidth = 0.6) +\n    \n    # remove all the other lines\n    theme(line = element_blank(), \n          panel.background = element_rect(fill = \"white\",\n                                          colour = \"white\",\n                                          linetype = \"solid\")) +\n    \n    # define axis labels\n    labs(x = as.expression(bquote(rho~\"=\"~.(ro.value))),\n         y = \"\") +\n    \n    # add annotations\n    geom_text(x = x1, y = y1, label = \"Part 1\") +\n    geom_text(x = x2, y = y2, label = \"Part 2\") +\n    geom_text(x = x3, y = y3, label = p1) +\n    geom_text(x = x4, y = y4, label = p2) +\n  \n    # define consistent axis breaks etc.\n    scale_x_continuous(breaks = breaks, lim = limits) +\n    scale_y_continuous(breaks = breaks, lim = limits)\n    \n    plot\n  \n}\n\n# Wrapper function with a consistent parameter handling approach\nplot_scatter_with_defaults &lt;- function(DT, figure = \"oc1\") {\n  # Define defaults for each set\n  defaults &lt;- list(\n    oc1 = list(outcome.y = \"b_2\", outcome.x = \"b_1\",\n               breaks = seq(from = -1, to = 1, by = 0.5), \n               limits = c(-1, 1), \n               x1 = 0.9, x2 = 0.3, x3 = -0.6, x4 = 0.6, \n               y1 = -0.115, y2 = 1.05, y3 = 0.7, y4 = -0.7),\n    oc2 = list(outcome.y = \"a_2\", outcome.x = \"a_1\",\n               breaks = seq(from = -2, to = 4, by = 1), \n               limits = c(-2, 4), \n               x1 = 3.4, x2 = 0.8, x3 = -1.5, x4 = 1.5, \n               y1 = -0.4, y2 = 0.39, y3 = 1.9, y4 = -1.9),\n    oc3 = list(outcome.y = \"E1_2\", outcome.x = \"E1_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20),\n    oc4 = list(outcome.y = \"E2_2\", outcome.x = \"E2_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20),\n    oc5 = list(outcome.y = \"E3_2\", outcome.x = \"E3_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20),\n    oc6 = list(outcome.y = \"E12_2\", outcome.x = \"E12_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20),\n    oc7 = list(outcome.y = \"E13_2\", outcome.x = \"E13_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20),\n    oc8 = list(outcome.y = \"E23_2\", outcome.x = \"E23_1\",\n               breaks = seq(from = 0, to = 100, by = 50), \n               limits = c(0, 101), \n               x1 = 90, x2 = 15, x3 = 15, x4 = 90, \n               y1 = 5, y2 = 100, y3 = 80, y4 = 20)\n  )\n  \n  # Remove the non-required default params before calling the plot function\n  default_params &lt;- defaults[[figure]]\n  \n  # Combine all parameters\n  args &lt;- c(list(DT = DT), default_params)\n  \n  # Call the original plot function with the combined arguments\n  do.call(plot_scatter, args)\n}"
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.1",
    "href": "C-online-appendix.html#figure-oc.1",
    "title": "10  Online Appendix C",
    "section": "10.2 Figure OC.1",
    "text": "10.2 Figure OC.1\nIn what follows, we will call the custom functions defined above.\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc1\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc1\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc1\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc1\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc1\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc1\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc1\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc1\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.1: Scatterplot of the ambiguity index b. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.2",
    "href": "C-online-appendix.html#figure-oc.2",
    "title": "10  Online Appendix C",
    "section": "10.3 Figure OC.2",
    "text": "10.3 Figure OC.2\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc2\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc2\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc2\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc2\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc2\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc2\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc2\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc2\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.2: Scatterplot of the ambiguity index a. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.3",
    "href": "C-online-appendix.html#figure-oc.3",
    "title": "10  Online Appendix C",
    "section": "10.4 Figure OC.3",
    "text": "10.4 Figure OC.3\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc3\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc3\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc3\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc3\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc3\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc3\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc3\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc3\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.3: Scatterplot of the matching probabilities for event E1. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.4",
    "href": "C-online-appendix.html#figure-oc.4",
    "title": "10  Online Appendix C",
    "section": "10.5 Figure OC.4",
    "text": "10.5 Figure OC.4\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc4\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc4\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc4\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc4\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc4\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc4\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc4\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc4\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.4: Scatterplot of the matching probabilities for event E2. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.5",
    "href": "C-online-appendix.html#figure-oc.5",
    "title": "10  Online Appendix C",
    "section": "10.6 Figure OC.5",
    "text": "10.6 Figure OC.5\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc5\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc5\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc5\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc5\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc5\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc5\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc5\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc5\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.5: Scatterplot of the matching probabilities for event E3. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.6",
    "href": "C-online-appendix.html#figure-oc.6",
    "title": "10  Online Appendix C",
    "section": "10.7 Figure OC.6",
    "text": "10.7 Figure OC.6\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc6\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc6\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc6\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc6\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc6\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc6\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc6\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc6\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.6: Scatterplot of the matching probabilities for event E12. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.7",
    "href": "C-online-appendix.html#figure-oc.7",
    "title": "10  Online Appendix C",
    "section": "10.8 Figure OC.7",
    "text": "10.8 Figure OC.7\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc7\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc7\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc7\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc7\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc7\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc7\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc7\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc7\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.7: Scatterplot of the matching probabilities for event E13. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "C-online-appendix.html#figure-oc.8",
    "href": "C-online-appendix.html#figure-oc.8",
    "title": "10  Online Appendix C",
    "section": "10.9 Figure OC.8",
    "text": "10.9 Figure OC.8\n\ntop1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE], figure = \"oc8\")\n\ntop2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE], figure = \"oc8\")\n\nmid1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"point\"], figure = \"oc8\")\n\nmid2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"interval\"], figure = \"oc8\")\n\nmid3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == FALSE & communication == \"both\"], figure = \"oc8\")\n\nbot1 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"point\"], figure = \"oc8\")\n\nbot2 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"interval\"], figure = \"oc8\")\n\nbot3 &lt;- plot_scatter_with_defaults(DT = wide_data[surprise == TRUE & communication == \"both\"], figure = \"oc8\")\n\n((top1|top2) / (mid1 | mid2 | mid3) / (bot1 | bot2 | bot3) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 10.8: Scatterplot of the matching probabilities for event E23. The relationship between part 1 and part 2 separated by treatments with correlation coefficients and percentages above and below the diagonal."
  },
  {
    "objectID": "D-online-appendix.html#setup",
    "href": "D-online-appendix.html#setup",
    "title": "11  Online Appendix D",
    "section": "11.1 Setup",
    "text": "11.1 Setup\n\n11.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n  install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\", \"patchwork\",\n          \"rstatix\", \"ggpubr\", \"glue\", \"lubridate\", \"plyr\", \n          \"lmtest\", \"sandwich\", \"stargazer\" # packages for regression tables\n)\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n11.1.2 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\n\n11.1.3 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)"
  },
  {
    "objectID": "D-online-appendix.html#subsample-1-good-comprehension-yes-or-rather-yes",
    "href": "D-online-appendix.html#subsample-1-good-comprehension-yes-or-rather-yes",
    "title": "11  Online Appendix D",
    "section": "11.2 Subsample 1: Good comprehension (yes or rather yes)",
    "text": "11.2 Subsample 1: Good comprehension (yes or rather yes)\n\nex_1_N &lt;- data[stage == 1 & str_detect(string = comprehension, pattern = \"yes\", negate = TRUE), .N]\n\nWe perceive the tasks as cognitively demanding for the experimental participants. Not understanding the tasks could have led to additional noise in the data set. To exclude this as a factor influencing our results, we excluded participants who self-reported not understanding the experiment well or rather well. In the process, we excluded 286 participants for this robustness check.\n::: {#tbl-OD1 .cell tbl-cap=’ ’}\ntmp &lt;- data[str_detect(string = comprehension, pattern = \"yes\", negate = FALSE)]\n\nols_1 &lt;- lm(formula = b ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on b\",\n          dep.var.caption = \"Dependent variable: b\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on b\n\n\n\n\n\n\n\n\n\nDependent variable: b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n0.005\n\n\n\n\n\n\n0.025\n\n\n-0.021\n\n\n0.013\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n(0.029)\n\n\n(0.029)\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n-0.035\n\n\n-0.048\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n-0.002\n\n\n-0.048\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.024***\n\n\n-0.038**\n\n\n-0.005\n\n\n-0.038**\n\n\n-0.013\n\n\n-0.022\n\n\n\n\n\n\n(0.009)\n\n\n(0.016)\n\n\n(0.018)\n\n\n(0.016)\n\n\n(0.015)\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.017\n\n\n\n\n\n\n0.032\n\n\n0.008\n\n\n0.010\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n(0.024)\n\n\n(0.022)\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n0.016\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n0.024\n\n\n-0.0001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.075***\n\n\n-0.063***\n\n\n-0.038*\n\n\n-0.063***\n\n\n-0.065***\n\n\n-0.098***\n\n\n\n\n\n\n(0.012)\n\n\n(0.019)\n\n\n(0.022)\n\n\n(0.019)\n\n\n(0.020)\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,438\n\n\n1,210\n\n\n1,228\n\n\n810\n\n\n820\n\n\n808\n\n\n\n\nR2\n\n\n0.001\n\n\n0.005\n\n\n0.006\n\n\n0.007\n\n\n0.001\n\n\n0.002\n\n\n\n\nAdjusted R2\n\n\n0.0001\n\n\n0.001\n\n\n0.001\n\n\n0.003\n\n\n-0.003\n\n\n-0.002\n\n\n\n\nResidual Std. Error\n\n\n0.306\n\n\n0.295\n\n\n0.317\n\n\n0.299\n\n\n0.311\n\n\n0.309\n\n\n\n\nF Statistic\n\n\n1.105\n\n\n1.167\n\n\n1.360\n\n\n1.834\n\n\n0.276\n\n\n0.442\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n:::\n::: {#tbl-OD2 .cell tbl-cap=’ ’}\nols_1 &lt;- lm(formula = a ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on a\",\n          dep.var.caption = \"Dependent variable: a\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on a\n\n\n\n\n\n\n\n\n\nDependent variable: a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n-0.044\n\n\n\n\n\n\n-0.008\n\n\n-0.033\n\n\n-0.091**\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n(0.046)\n\n\n(0.050)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n0.052\n\n\n-0.030\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.046)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n0.014\n\n\n-0.011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.048)\n\n\n(0.049)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.001\n\n\n0.014\n\n\n-0.009\n\n\n0.014\n\n\n0.024\n\n\n-0.041\n\n\n\n\n\n\n(0.021)\n\n\n(0.038)\n\n\n(0.036)\n\n\n(0.038)\n\n\n(0.035)\n\n\n(0.037)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.005\n\n\n\n\n\n\n-0.023\n\n\n-0.003\n\n\n0.040\n\n\n\n\n\n\n(0.030)\n\n\n\n\n\n\n(0.052)\n\n\n(0.050)\n\n\n(0.052)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n-0.055\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.053)\n\n\n(0.052)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n0.011\n\n\n0.030\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.052)\n\n\n(0.051)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.739***\n\n\n0.716***\n\n\n0.708***\n\n\n0.716***\n\n\n0.731***\n\n\n0.769***\n\n\n\n\n\n\n(0.019)\n\n\n(0.032)\n\n\n(0.034)\n\n\n(0.032)\n\n\n(0.036)\n\n\n(0.034)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,438\n\n\n1,210\n\n\n1,228\n\n\n810\n\n\n820\n\n\n808\n\n\n\n\nR2\n\n\n0.002\n\n\n0.001\n\n\n0.001\n\n\n0.001\n\n\n0.002\n\n\n0.006\n\n\n\n\nAdjusted R2\n\n\n0.0005\n\n\n-0.003\n\n\n-0.003\n\n\n-0.003\n\n\n-0.002\n\n\n0.002\n\n\n\n\nResidual Std. Error\n\n\n0.506\n\n\n0.501\n\n\n0.512\n\n\n0.501\n\n\n0.527\n\n\n0.491\n\n\n\n\nF Statistic\n\n\n1.376\n\n\n0.310\n\n\n0.214\n\n\n0.141\n\n\n0.427\n\n\n1.642\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\nrm(tmp)\n:::"
  },
  {
    "objectID": "D-online-appendix.html#subsample-2-no-wrong-answers-in-the-control-questions",
    "href": "D-online-appendix.html#subsample-2-no-wrong-answers-in-the-control-questions",
    "title": "11  Online Appendix D",
    "section": "11.3 Subsample 2: No wrong answers in the control questions",
    "text": "11.3 Subsample 2: No wrong answers in the control questions\n\nex_2_N &lt;- data[, length(unique(participant.label))] - data[wrong_answer_1==0 & wrong_answer_2==0, length(unique(participant.label))]\n\nUsing a similar rationale as in subsample 1, we excluded participants who had at least one error in the control questions. In doing so, we removed 321 participants. Apart from the different exclusion criterion, the code producing the corresponding tables looks exactly the same.\n::: {#tbl-OD3 .cell tbl-cap=’ ’}\ntmp &lt;- data[wrong_answer_1==0 & wrong_answer_2==0]\n\nols_1 &lt;- lm(formula = b ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on b\",\n          dep.var.caption = \"Dependent variable: b\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\",\n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on b\n\n\n\n\n\n\n\n\n\nDependent variable: b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n0.008\n\n\n\n\n\n\n0.018\n\n\n-0.023\n\n\n0.031\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n(0.027)\n\n\n(0.030)\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n-0.051*\n\n\n-0.038\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n-0.019\n\n\n-0.059**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.017*\n\n\n-0.041**\n\n\n-0.006\n\n\n-0.041**\n\n\n-0.0002\n\n\n-0.011\n\n\n\n\n\n\n(0.010)\n\n\n(0.017)\n\n\n(0.016)\n\n\n(0.017)\n\n\n(0.016)\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.010\n\n\n\n\n\n\n0.034\n\n\n0.009\n\n\n-0.012\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n(0.023)\n\n\n(0.022)\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n0.029\n\n\n-0.018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n0.040*\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.089***\n\n\n-0.066***\n\n\n-0.049**\n\n\n-0.066***\n\n\n-0.085***\n\n\n-0.117***\n\n\n\n\n\n\n(0.011)\n\n\n(0.017)\n\n\n(0.021)\n\n\n(0.017)\n\n\n(0.021)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,368\n\n\n1,172\n\n\n1,196\n\n\n802\n\n\n800\n\n\n766\n\n\n\n\nR2\n\n\n0.001\n\n\n0.005\n\n\n0.006\n\n\n0.006\n\n\n0.001\n\n\n0.003\n\n\n\n\nAdjusted R2\n\n\n-0.0003\n\n\n0.001\n\n\n0.002\n\n\n0.002\n\n\n-0.003\n\n\n-0.001\n\n\n\n\nResidual Std. Error\n\n\n0.302\n\n\n0.290\n\n\n0.312\n\n\n0.288\n\n\n0.314\n\n\n0.301\n\n\n\n\nF Statistic\n\n\n0.782\n\n\n1.255\n\n\n1.480\n\n\n1.654\n\n\n0.256\n\n\n0.680\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\n:::\n::: {#tbl-OD4 .cell tbl-cap=’ ’}\nols_1 &lt;- lm(formula = a ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on a\",\n          dep.var.caption = \"Dependent variable: a\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on a\n\n\n\n\n\n\n\n\n\nDependent variable: a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n-0.024\n\n\n\n\n\n\n0.013\n\n\n-0.022\n\n\n-0.065\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n(0.049)\n\n\n(0.048)\n\n\n(0.045)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n0.062\n\n\n-0.016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.047)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n0.039\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.048)\n\n\n(0.049)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.005\n\n\n0.031\n\n\n-0.002\n\n\n0.031\n\n\n-0.010\n\n\n-0.038\n\n\n\n\n\n\n(0.021)\n\n\n(0.039)\n\n\n(0.037)\n\n\n(0.039)\n\n\n(0.033)\n\n\n(0.039)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.013\n\n\n\n\n\n\n-0.033\n\n\n0.011\n\n\n0.064\n\n\n\n\n\n\n(0.030)\n\n\n\n\n\n\n(0.054)\n\n\n(0.049)\n\n\n(0.055)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n-0.070\n\n\n0.028\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.055)\n\n\n(0.054)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n-0.041\n\n\n0.003\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.051)\n\n\n(0.052)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.734***\n\n\n0.701***\n\n\n0.714***\n\n\n0.701***\n\n\n0.740***\n\n\n0.763***\n\n\n\n\n\n\n(0.019)\n\n\n(0.034)\n\n\n(0.035)\n\n\n(0.034)\n\n\n(0.034)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,368\n\n\n1,172\n\n\n1,196\n\n\n802\n\n\n800\n\n\n766\n\n\n\n\nR2\n\n\n0.0004\n\n\n0.001\n\n\n0.0003\n\n\n0.0005\n\n\n0.0003\n\n\n0.002\n\n\n\n\nAdjusted R2\n\n\n-0.001\n\n\n-0.003\n\n\n-0.004\n\n\n-0.003\n\n\n-0.003\n\n\n-0.002\n\n\n\n\nResidual Std. Error\n\n\n0.495\n\n\n0.486\n\n\n0.505\n\n\n0.511\n\n\n0.498\n\n\n0.477\n\n\n\n\nF Statistic\n\n\n0.281\n\n\n0.339\n\n\n0.063\n\n\n0.128\n\n\n0.084\n\n\n0.605\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\nrm(tmp)\n:::"
  },
  {
    "objectID": "D-online-appendix.html#subsample-3-survey-experiment-completion-time-10-90-quantile",
    "href": "D-online-appendix.html#subsample-3-survey-experiment-completion-time-10-90-quantile",
    "title": "11  Online Appendix D",
    "section": "11.4 Subsample 3: Survey experiment completion time 10%-90% quantile",
    "text": "11.4 Subsample 3: Survey experiment completion time 10%-90% quantile\n\nlo_quantile &lt;- data[, quantile(x = completion_time, probs = 0.1)]\nhi_quantile &lt;- data[, quantile(x = completion_time, probs = 0.9)]\n\nlo_time &lt;- seconds_to_period(lo_quantile)\nhi_time &lt;- seconds_to_period(hi_quantile)\n\nex_3_N &lt;- data[, length(unique(participant.label))] - data[completion_time &gt; lo_quantile & completion_time &lt; hi_quantile, length(unique(participant.label))]\n\nWe believe that excessively fast participants could introduce additional noise. We also believe that participants doing other things on the side and who may have been very slow in the experiment could cause a similar effect. As a result, we removed participants who took less than 8 minutes 41 (10 percent quantile) and more than 40 minutes 51 seconds (90 percent quantile). This is equivalent to a removal of 303 participants.\nApart from the different exclusion criterion, the code producing the corresponding tables looks exactly the same.\n::: {#tbl-OD5 .cell tbl-cap=’ ’}\ntmp &lt;- data[completion_time &gt; lo_quantile & completion_time &lt; hi_quantile]\n\nols_1 &lt;- lm(formula = b ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on b\",\n          dep.var.caption = \"Dependent variable: b\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on b\n\n\n\n\n\n\n\n\n\nDependent variable: b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n0.011\n\n\n\n\n\n\n0.028\n\n\n-0.020\n\n\n0.027\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n(0.027)\n\n\n(0.029)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n-0.020\n\n\n-0.020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n0.011\n\n\n-0.037\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.022**\n\n\n-0.039**\n\n\n-0.003\n\n\n-0.039**\n\n\n-0.016\n\n\n-0.008\n\n\n\n\n\n\n(0.010)\n\n\n(0.016)\n\n\n(0.016)\n\n\n(0.016)\n\n\n(0.017)\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.008\n\n\n\n\n\n\n0.037\n\n\n0.006\n\n\n-0.020\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n(0.023)\n\n\n(0.023)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n0.031\n\n\n-0.026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n0.023\n\n\n-0.008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.079***\n\n\n-0.076***\n\n\n-0.048**\n\n\n-0.076***\n\n\n-0.065***\n\n\n-0.095***\n\n\n\n\n\n\n(0.011)\n\n\n(0.016)\n\n\n(0.021)\n\n\n(0.016)\n\n\n(0.021)\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,404\n\n\n1,198\n\n\n1,206\n\n\n808\n\n\n800\n\n\n796\n\n\n\n\nR2\n\n\n0.002\n\n\n0.004\n\n\n0.004\n\n\n0.010\n\n\n0.001\n\n\n0.002\n\n\n\n\nAdjusted R2\n\n\n0.0003\n\n\n-0.001\n\n\n0.00002\n\n\n0.006\n\n\n-0.002\n\n\n-0.002\n\n\n\n\nResidual Std. Error\n\n\n0.297\n\n\n0.286\n\n\n0.307\n\n\n0.277\n\n\n0.303\n\n\n0.311\n\n\n\n\nF Statistic\n\n\n1.277\n\n\n0.852\n\n\n1.005\n\n\n2.589*\n\n\n0.353\n\n\n0.497\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\n:::\n::: {#tbl-OD6 .cell tbl-cap=’ ’}\nols_1 &lt;- lm(formula = a ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on a\",\n          dep.var.caption = \"Dependent variable: a\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on a\n\n\n\n\n\n\n\n\n\nDependent variable: a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n-0.015\n\n\n\n\n\n\n0.039\n\n\n-0.011\n\n\n-0.074*\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n(0.048)\n\n\n(0.051)\n\n\n(0.045)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n0.065\n\n\n-0.048\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.047)\n\n\n(0.046)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n0.043\n\n\n-0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.051)\n\n\n(0.049)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.004\n\n\n0.026\n\n\n-0.026\n\n\n0.026\n\n\n-0.003\n\n\n-0.035\n\n\n\n\n\n\n(0.023)\n\n\n(0.040)\n\n\n(0.037)\n\n\n(0.040)\n\n\n(0.038)\n\n\n(0.038)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n-0.016\n\n\n\n\n\n\n-0.053\n\n\n-0.040\n\n\n0.046\n\n\n\n\n\n\n(0.031)\n\n\n\n\n\n\n(0.055)\n\n\n(0.052)\n\n\n(0.052)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n-0.062\n\n\n0.037\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.056)\n\n\n(0.051)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n-0.030\n\n\n-0.017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.056)\n\n\n(0.051)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.733***\n\n\n0.698***\n\n\n0.736***\n\n\n0.698***\n\n\n0.740***\n\n\n0.763***\n\n\n\n\n\n\n(0.020)\n\n\n(0.034)\n\n\n(0.034)\n\n\n(0.034)\n\n\n(0.038)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,404\n\n\n1,198\n\n\n1,206\n\n\n808\n\n\n800\n\n\n796\n\n\n\n\nR2\n\n\n0.001\n\n\n0.001\n\n\n0.001\n\n\n0.001\n\n\n0.002\n\n\n0.004\n\n\n\n\nAdjusted R2\n\n\n-0.001\n\n\n-0.003\n\n\n-0.003\n\n\n-0.003\n\n\n-0.002\n\n\n-0.0002\n\n\n\n\nResidual Std. Error\n\n\n0.513\n\n\n0.520\n\n\n0.506\n\n\n0.517\n\n\n0.541\n\n\n0.480\n\n\n\n\nF Statistic\n\n\n0.560\n\n\n0.348\n\n\n0.348\n\n\n0.213\n\n\n0.443\n\n\n0.956\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\nrm(tmp)\n:::"
  },
  {
    "objectID": "D-online-appendix.html#subsample-4-weakly-monotonic-answers-overlinem_sleqoverlinem_c",
    "href": "D-online-appendix.html#subsample-4-weakly-monotonic-answers-overlinem_sleqoverlinem_c",
    "title": "11  Online Appendix D",
    "section": "11.5 Subsample 4: Weakly monotonic answers \\((\\overline{m_s}\\leq\\overline{m_c})\\)",
    "text": "11.5 Subsample 4: Weakly monotonic answers \\((\\overline{m_s}\\leq\\overline{m_c})\\)\n\nviolators &lt;- data[mc &lt; ms, unique(participant.label)]\n\nIn this subsample, we removed participants who violated weak monotonicity for the averaged single vs. combined events (\\(\\overline{m_s}\\leq\\overline{m_c}\\)) at least once (either part 1 or part 2). This ensures that index \\(a\\) is 1 or less than 1. Baillon et al. (2018) also use this robustness check. We excluded 537 participants.\nApart from the different exclusion criterion, the code producing the corresponding tables looks exactly the same.\n::: {#tbl-OD7 .cell tbl-cap=’ ’}\ntmp &lt;- data[!(participant.label %in% violators)]\n\nols_1 &lt;- lm(formula = b ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = b ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = b ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on b\",\n          dep.var.caption = \"Dependent variable: b\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\n\n\n\nLinear regressions: Treatment effects on b\n\n\n\n\n\n\n\n\n\nDependent variable: b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n0.011\n\n\n\n\n\n\n0.025\n\n\n-0.002\n\n\n0.012\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n(0.030)\n\n\n(0.031)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n-0.050\n\n\n-0.063**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.031)\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n0.004\n\n\n-0.023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n(0.032)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n-0.017**\n\n\n-0.027*\n\n\n-0.013\n\n\n-0.027*\n\n\n-0.023\n\n\n0.0005\n\n\n\n\n\n\n(0.008)\n\n\n(0.014)\n\n\n(0.016)\n\n\n(0.014)\n\n\n(0.015)\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n0.002\n\n\n\n\n\n\n0.014\n\n\n0.004\n\n\n-0.013\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n(0.022)\n\n\n(0.021)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n0.027\n\n\n-0.00004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n0.004\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.021)\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-0.071***\n\n\n-0.057***\n\n\n-0.032\n\n\n-0.057***\n\n\n-0.053**\n\n\n-0.106***\n\n\n\n\n\n\n(0.012)\n\n\n(0.020)\n\n\n(0.023)\n\n\n(0.020)\n\n\n(0.021)\n\n\n(0.024)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n1,936\n\n\n926\n\n\n1,010\n\n\n650\n\n\n654\n\n\n632\n\n\n\n\nR2\n\n\n0.001\n\n\n0.006\n\n\n0.008\n\n\n0.005\n\n\n0.001\n\n\n0.0003\n\n\n\n\nAdjusted R2\n\n\n-0.0004\n\n\n0.0003\n\n\n0.003\n\n\n0.0004\n\n\n-0.003\n\n\n-0.004\n\n\n\n\nResidual Std. Error\n\n\n0.290\n\n\n0.280\n\n\n0.298\n\n\n0.273\n\n\n0.300\n\n\n0.296\n\n\n\n\nF Statistic\n\n\n0.744\n\n\n1.052\n\n\n1.614\n\n\n1.079\n\n\n0.265\n\n\n0.069\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\n:::\n\nols_1 &lt;- lm(formula = a ~ surprise + treated + surprise * treated,\n            data = tmp)\nse_1  &lt;- coeftest(x = ols_1, \n                  vcov = vcovCL(ols_1,\n                                cluster = ~tmp$participant.label,\n                                type = \"HC1\"))\n\nols_2 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == FALSE))\nse_2  &lt;- coeftest(x = ols_2, \n                  vcov = vcovCL(ols_2,\n                                cluster = tmp[surprise == FALSE, participant.label],\n                                type = \"HC1\"))\n\nols_3 &lt;- lm(formula = a ~ communication + treated + communication * treated, \n            data = tmp,\n            subset = (surprise == TRUE))\nse_3  &lt;- coeftest(x = ols_3, \n                  vcov = vcovCL(ols_3,\n                                cluster = tmp[surprise == TRUE, participant.label],\n                                type = \"HC1\"))\n\nols_4 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"point\"))\nse_4  &lt;- coeftest(x = ols_4, \n                  vcov = vcovCL(ols_4,\n                                cluster = tmp[communication == \"point\", participant.label],\n                                type = \"HC1\"))\n\nols_5 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"interval\"))\nse_5  &lt;- coeftest(x = ols_5, \n                  vcov = vcovCL(ols_5,\n                                cluster = tmp[communication == \"interval\", participant.label],\n                                type = \"HC1\"))\n\nols_6 &lt;- lm(formula = a ~ surprise + treated + surprise * treated, \n            data = tmp,\n            subset = (communication == \"both\"))\nse_6  &lt;- coeftest(x = ols_6, \n                  vcov = vcovCL(ols_6,\n                                cluster = tmp[communication == \"both\", participant.label],\n                                type = \"HC1\"))\n\n\n\nse &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\np  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n\nstargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n          align = TRUE, \n          se = se, \n          p = p,   \n          title = \"Linear regressions: Treatment effects on a\",\n          dep.var.caption = \"Dependent variable: a\",\n          dep.var.labels = \" \",\n          model.names = FALSE,\n          column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n          covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"interval x stage2\", \"both x stage2\", \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          notes = c(\"The underlying standard errors (“HC1”) are clustered at the individual level and \",\n                    \"estimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\"),\n          notes.align = \"l\",\n          df = FALSE)\nrm(tmp)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-0.033\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.043\n\n\n\n\n\n\n\n\n\n\n\n\n-0.012\n\n\n\n\n\n\n\n\n\n\n\n\n-0.046\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.040)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.042)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.041)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n0.017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.043)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.038)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.017\n\n\n\n\n\n\n\n\n\n\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.043)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.039)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n\n\n\n\n\n\n\n\n\n\n-0.043***\n\n\n\n\n\n\n\n\n\n\n\n\n-0.018\n\n\n\n\n\n\n\n\n\n\n\n\n-0.050*\n\n\n\n\n\n\n\n\n\n\n\n\n-0.018\n\n\n\n\n\n\n\n\n\n\n\n\n-0.061**\n\n\n\n\n\n\n\n\n\n\n\n\n-0.053*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.032\n\n\n\n\n\n\n\n\n\n\n\n\n0.021\n\n\n\n\n\n\n\n\n\n\n\n\n0.016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.038)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.041)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.039)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.035\n\n\n\n\n\n\n\n\n\n\n\n\n0.013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.038)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.039)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.043\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.039)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.040)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n0.538***\n\n\n\n\n\n\n\n\n\n\n\n\n0.537***\n\n\n\n\n\n\n\n\n\n\n\n\n0.494***\n\n\n\n\n\n\n\n\n\n\n\n\n0.537***\n\n\n\n\n\n\n\n\n\n\n\n\n0.520***\n\n\n\n\n\n\n\n\n\n\n\n\n0.557***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.027)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n1,936\n\n\n\n\n\n\n\n\n\n\n\n\n926\n\n\n\n\n\n\n\n\n\n\n\n\n1,010\n\n\n\n\n\n\n\n\n\n\n\n\n650\n\n\n\n\n\n\n\n\n\n\n\n\n654\n\n\n\n\n\n\n\n\n\n\n\n\n632\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.003\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n-0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n-0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n0.383\n\n\n\n\n\n\n\n\n\n\n\n\n0.386\n\n\n\n\n\n\n\n\n\n\n\n\n0.380\n\n\n\n\n\n\n\n\n\n\n\n\n0.374\n\n\n\n\n\n\n\n\n\n\n\n\n0.402\n\n\n\n\n\n\n\n\n\n\n\n\n0.372\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n3.169**\n\n\n\n\n\n\n\n\n\n\n\n\n1.126\n\n\n\n\n\n\n\n\n\n\n\n\n0.772\n\n\n\n\n\n\n\n\n\n\n\n\n1.900\n\n\n\n\n\n\n\n\n\n\n\n\n0.880\n\n\n\n\n\n\n\n\n\n\n\n\n1.298\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe underlying standard errors (“HC1”) are clustered at the individual level and\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimated with the R package sandwich (Zeileis 2004; Zeileis et al. 2020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaillon, Aurélien, Zhenxing Huang, Asli Selim, and Peter P. Wakker. 2018. “Measuring Ambiguity Attitudes for All (Natural) Events.” Econometrica 86 (5): 1839–58. https://doi.org/10.3982/ECTA14370."
  },
  {
    "objectID": "02-tables.html#table-2",
    "href": "02-tables.html#table-2",
    "title": "2  Tables",
    "section": "3.2 Table 2",
    "text": "3.2 Table 2\nThis table was created in a manual process, the corresponding summary statistics can be queried using the following code, where surprise == FALSE selects the confirmation treatment arm:\n\ndata[communication == \"point\" & surprise == FALSE,      # choose condition\n     .(mean = round(mean(b, na.rm = TRUE), digits = 2), # choose variable\n       sd = round(sd(b, na.rm = TRUE), digits = 2)),    # choose variable\n     by = stage] %&gt;% \n  kable()\n\n\n\n\nstage\nmean\nsd\n\n\n\n\n1\n-0.05\n0.27\n\n\n2\n-0.09\n0.31\n\n\n\n\n\nThe number of observations by treatment can be queried using the following code:\n\ndata[, \n     .(N = length(unique(participant.label))), \n     by = c(\"communication\", \"surprise\")][order(surprise, communication)] %&gt;%\n  kable()\n\n\n\n\ncommunication\nsurprise\nN\n\n\n\n\npoint\nFALSE\n255\n\n\nboth\nFALSE\n247\n\n\ninterval\nFALSE\n243\n\n\npoint\nTRUE\n252\n\n\nboth\nTRUE\n250\n\n\ninterval\nTRUE\n258\n\n\n\n\n# alternatively:\n# data[stage == 2, \n#      .N, \n#      by = c(\"communication\", \"surprise\")][order(surprise, communication)]\n\n\n# Melt the data\nlong_df &lt;- melt(data,\n                id.vars = c(\"stage\", \"surprise\", \"communication\"),\n                measure.vars = c(\"b\", \"a\", \"E1\", \"E2\", \"E3\", \"E12\", \"E13\", \"E23\"),\n                variable.name = \"Variable\",\n                value.name = \"Value\")\n\n# Function to calculate mean and sd\ncalculate_stats &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE))\n}\n\n# Calculate pooled summary\npooled_summary &lt;- long_df[, as.list(calculate_stats(Value)), by = .(Variable, stage)]\nsetnames(pooled_summary, c(\"mean\", \"sd\"), c(\"mean_pooled\", \"sd_pooled\"))\n\n# Calculate summary by treatment\nsummary_tmp &lt;- long_df[, as.list(calculate_stats(Value)), \n                       by = .(surprise, communication, Variable, stage)]\n\n# Reshape summary_tmp to wide format\nsummary_wide &lt;- dcast(summary_tmp, \n                      Variable + stage ~ surprise + communication, \n                      value.var = c(\"mean\", \"sd\"))\n\n# Merge pooled summary with reshaped summary\nsummary_table_wide &lt;- merge(x = pooled_summary,\n                            y = summary_wide, \n                            by = c(\"Variable\", \"stage\"))\n\n# Function to format mean and sd without line break\nformat_mean_sd &lt;- function(mean, sd) {\n  sprintf(\"%.2f (%.2f)\", mean, sd)\n}\n\n# Apply formatting\ncols_to_format &lt;- names(summary_table_wide)[3:length(names(summary_table_wide))]\nsummary_table_wide[, (cols_to_format) := lapply(.SD, as.numeric), .SDcols = cols_to_format]\nsummary_table_wide[, c(\"Pooled\", \"Confirmation_point\", \"Confirmation_both\", \"Confirmation_interval\", \n                       \"Contradiction_point\", \"Contradiction_both\", \"Contradiction_interval\") := \n                     .(format_mean_sd(mean_pooled, sd_pooled),\n                       format_mean_sd(mean_FALSE_point, sd_FALSE_point),\n                       format_mean_sd(mean_FALSE_both, sd_FALSE_both),\n                       format_mean_sd(mean_FALSE_interval, sd_FALSE_interval),\n                       format_mean_sd(mean_TRUE_point, sd_TRUE_point),\n                       format_mean_sd(mean_TRUE_both, sd_TRUE_both),\n                       format_mean_sd(mean_TRUE_interval, sd_TRUE_interval))]\n\n# Select only the formatted columns\nsummary_table_final &lt;- summary_table_wide[, .(Variable, stage, Pooled, \n                                              Confirmation_point, Confirmation_both, Confirmation_interval,\n                                              Contradiction_point, Contradiction_both, Contradiction_interval)]\n\n# Create gt table\nsummary_table_final %&gt;% \n  gt(groupname_col = \"Variable\") %&gt;% \n  cols_label(\n    stage = \"Stage\",\n    Pooled = \"Pooled\",\n    Confirmation_point = \"Point\",\n    Confirmation_both = \"Point + interval\",\n    Confirmation_interval = \"Interval\",\n    Contradiction_point = \"Point\",\n    Contradiction_both = \"Point + interval\",\n    Contradiction_interval = \"Interval\"\n  ) %&gt;%\n  tab_spanner(\n    label = \"Confirmation\",\n    columns = c(Confirmation_point, Confirmation_both, Confirmation_interval)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Contradiction\",\n    columns = c(Contradiction_point, Contradiction_both, Contradiction_interval)\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = c(Variable, stage)\n  ) %&gt;%\n  cols_align(\n    align = \"center\",\n    columns = c(Pooled, Confirmation_point, Confirmation_both, Confirmation_interval,\n                Contradiction_point, Contradiction_both, Contradiction_interval)\n  ) %&gt;%\n  opt_row_striping() %&gt;%\n  tab_options(\n    table.font.size = px(12),\n    data_row.padding = px(4)\n  )\n\n\n\n\n\n  \n    \n      Stage\n      Pooled\n      \n        Confirmation\n      \n      \n        Contradiction\n      \n    \n    \n      Point\n      Point + interval\n      Interval\n      Point\n      Point + interval\n      Interval\n    \n  \n  \n    \n      b\n    \n    1\n-0.07 (0.30)\n-0.05 (0.27)\n-0.09 (0.30)\n-0.07 (0.29)\n-0.04 (0.31)\n-0.08 (0.31)\n-0.08 (0.31)\n    2\n-0.08 (0.32)\n-0.09 (0.31)\n-0.09 (0.32)\n-0.08 (0.32)\n-0.04 (0.31)\n-0.10 (0.34)\n-0.07 (0.34)\n    \n      a\n    \n    1\n0.72 (0.49)\n0.71 (0.50)\n0.78 (0.47)\n0.73 (0.51)\n0.71 (0.49)\n0.68 (0.44)\n0.69 (0.51)\n    2\n0.71 (0.54)\n0.73 (0.54)\n0.73 (0.51)\n0.73 (0.56)\n0.69 (0.54)\n0.70 (0.53)\n0.69 (0.56)\n    \n      E1\n    \n    1\n47.41 (20.96)\n46.65 (19.05)\n49.08 (20.32)\n47.98 (21.74)\n45.16 (20.53)\n46.65 (21.02)\n48.93 (22.84)\n    2\n50.19 (25.46)\n47.61 (25.00)\n46.58 (25.10)\n46.35 (24.46)\n52.63 (24.79)\n56.24 (26.81)\n51.57 (25.24)\n    \n      E2\n    \n    1\n50.06 (20.80)\n50.11 (19.95)\n51.67 (20.49)\n50.28 (21.62)\n48.61 (20.08)\n51.05 (20.78)\n48.70 (21.84)\n    2\n50.75 (23.38)\n54.34 (22.15)\n55.01 (23.46)\n53.28 (24.48)\n45.51 (21.29)\n48.63 (24.14)\n47.89 (23.23)\n    \n      E3\n    \n    1\n48.43 (20.34)\n46.28 (19.22)\n51.09 (20.01)\n48.48 (20.58)\n47.51 (21.53)\n48.47 (19.36)\n48.83 (21.11)\n    2\n46.70 (24.49)\n48.44 (22.04)\n49.31 (23.08)\n48.47 (23.55)\n42.09 (25.44)\n45.72 (26.34)\n46.27 (25.70)\n    \n      E12\n    \n    1\n58.13 (20.00)\n57.13 (19.64)\n58.80 (19.76)\n59.20 (19.23)\n57.57 (20.24)\n58.02 (21.17)\n58.11 (20.00)\n    2\n61.94 (24.17)\n60.22 (22.64)\n61.48 (21.98)\n58.80 (23.39)\n62.03 (26.61)\n66.30 (25.07)\n62.72 (24.54)\n    \n      E13\n    \n    1\n55.60 (20.11)\n55.41 (19.15)\n55.89 (20.00)\n54.06 (21.15)\n52.73 (20.07)\n57.07 (19.93)\n58.31 (20.09)\n    2\n55.93 (23.45)\n54.08 (23.73)\n52.53 (24.57)\n54.12 (23.32)\n56.94 (21.92)\n59.55 (24.11)\n58.19 (22.41)\n    \n      E23\n    \n    1\n60.42 (22.37)\n59.32 (23.18)\n59.63 (22.24)\n60.04 (22.48)\n59.58 (23.51)\n62.71 (21.38)\n61.24 (21.38)\n    2\n58.37 (24.38)\n62.63 (24.44)\n63.52 (23.92)\n62.12 (23.02)\n52.01 (24.71)\n54.40 (24.54)\n55.77 (23.29)"
  },
  {
    "objectID": "E-online-appendix.html#setup",
    "href": "E-online-appendix.html#setup",
    "title": "12  Online Appendix E",
    "section": "12.1 Setup",
    "text": "12.1 Setup\n\n12.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\", \"patchwork\",\n          \"rstatix\", \"ggpubr\", \"glue\", \"lubridate\", \"plyr\", \n          \"lmtest\", \"sandwich\", \"stargazer\" # packages for regression tables\n          )\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n12.1.2 Read Data\n\n# data &lt;- data.table::fread(file = \"../data/processed/full.csv\")\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\n\n12.1.3 Manipulate Data\n\ncols &lt;- str_subset(string = names(data), pattern = \"E\\\\d+\")\ndata[, \n     str_replace_all(string = cols, pattern = \"^E\", replacement = \"m\") := lapply(.SD, function(x) x / 100), \n     .SDcols = cols] \n\n\ndata[, p1 := (m1 - m23) / 6 / (mc - ms) + 0.5]\ndata[, p2 := (m2 - m13) / 6 / (mc - ms) + 0.5]\ndata[, p3 := (m3 - m12) / 6 / (mc - ms) + 0.5]\n\n\nstrict_violators &lt;- data[a &gt;= 1 | \n                           E1 &gt; E12 | E1 &gt; E13 | \n                           E2 &gt; E12 | E2 &gt; E23 |\n                           E3 &gt; E13 | E3 &gt; E23, \n                         unique(participant.label)]\nsubset &lt;- data[!(participant.label %in% strict_violators)]\n\n\nwide_subset &lt;- data.table::dcast(subset, \n                                 participant.label + surprise + communication ~ stage, \n                                 value.var = c(\"p1\", \"p2\", \"p3\"))\n\nsetorder(wide_subset, surprise, communication, participant.label)\n\n\nwide_subset[, euclidian_distance := sqrt((p1_1 - p1_2)^2 +\n                                           (p2_1 - p2_2)^2 +\n                                           (p3_1 - p3_2)^2)]\n\n\n\n12.1.4 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)\n\n\n\n12.1.5 Helper Function\n\nplot_bars2 &lt;- function(data, response = \"p\", surprise_sub = NA, limits = ylim(-0.05, 1.02)){\n  \n  if(response == \"p1\" | response == \"p2\" | response == \"p3\"){\n      y_1 = 0.6\n      y_2 = 0.4\n    } else {\n      y_1 = 1.4\n      y_2 = 1\n    }\n  \n  if(!is.na(surprise_sub)){\n    # Plot bottom panels\n    tmp &lt;- data[surprise == surprise_sub]\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    if(surprise_sub){\n      title &lt;- \"Surprising Condition\"\n    } else {\n      title &lt;- \"Confirming Condition\"\n    }\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(communication) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ communication) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    plot_bottom &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(communication),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"communication\") +\n      labs(title = \"\",\n           x = \" Surprising Condition\",\n           y = glue(\" {response}\"))\n    \n    rm(tmp)\n    \n    plot_bottom\n  } else {\n    # Plot the top panel\n    tmp &lt;- data\n    names(tmp)[names(tmp) == response] &lt;- 'outcome'\n    \n    title &lt;- \"Both Conditions\"\n    \n    test_stats_1 &lt;- tmp %&gt;% \n      group_by(surprise) %&gt;%\n      wilcox_test(formula = outcome ~ stage,\n                  paired = T) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    \n    \n    test_stats_2 &lt;- tmp %&gt;% \n      group_by(stage) %&gt;%\n      wilcox_test(formula = outcome ~ surprise) %&gt;% \n      adjust_pvalue(method = \"none\") %&gt;%\n      add_significance(p.col = \"p.adj\",\n                       cutpoints = c(0, 0.01, 0.05, 0.1, 1),\n                       symbols = c( \"***\", \"**\", \"*\", \"ns\")) %&gt;%\n      as.data.table()\n    test_stats_2 &lt;- test_stats_2[stage == 2]\n    \n    \n    plot_top &lt;- ggplot(data = tmp,\n           mapping = aes(x = as.factor(surprise),\n                         y = outcome)) +\n        geom_bar(aes(fill = stage),\n                 position = \"dodge\", \n                 stat = \"summary\", \n                 fun = \"mean\") + \n      limits +\n      scale_fill_manual(values=c(\"black\", \"gray\")) +\n      theme_classic() +\n      stat_pvalue_manual(data = test_stats_2,\n                         label = \"{p} ({p.adj.signif})\", \n                         step.group.by = \"stage\",\n                         tip.length = 0, \n                         step.increase = 0.1, \n                         y.position = y_1) +\n      stat_pvalue_manual(data = test_stats_1,\n                         label = \"{p} ({p.adj.signif})\",\n                         y.position = y_2,\n                         tip.length = 0,\n                         x = \"surprise\") +\n      labs(title = \"\",\n           x = \" Surprising Condition\",\n           y = glue(\" {response}\"))\n    \n    rm(tmp)\n    \n    plot_top\n  }\n}"
  },
  {
    "objectID": "E-online-appendix.html#figures-tables",
    "href": "E-online-appendix.html#figures-tables",
    "title": "12  Online Appendix E",
    "section": "12.2 Figures & Tables",
    "text": "12.2 Figures & Tables\nWe now consider the effects of information on so-called ambiguity neutral probabilities which have been suggested in Li, Turmunkh, and Wakker (2019). This analysis complements the investigations on the effect on the probability equivalents for the individual events that are discussed in the main part of the paper.\nAmbiguity-neutral probabilities are based on finding the neo-additive probability distribution (e.g., Baillon et al. 2017, 2021) with weights \\(w(E) = \\tau + \\sigma P(E)\\) given to events \\(E\\) that minimizes the Euclidian distance to the observed matching probabilities distribution. Li, Turmunkh, and Wakker (2019). show that \\(\\sigma = 1-a\\), \\(\\tau = b - (1-a)/2\\) and that the ambiguity-neutral probabilities \\((p_1,p_2,p_3)\\) are given by the following expression (see their equation (3.3)):\n\\[\n\\begin{aligned}\np_i &= \\frac{3(\\overline{m_c} - \\overline{m_s}) + 3m_i - 3m_{jk} + 2(1-a)}{6(1-a)} \\\\\n&= \\frac{3(\\overline{m_c} - \\overline{m_s}) + 3m_i - 3m_{jk} + 2(1-(3 \\times (\\frac{1}{3} - (\\overline{m_c} - \\overline{m_s}))))}{6(1-(3 \\times (\\frac{1}{3} - (\\overline{m_c} - \\overline{m_s}))))} \\\\\n&= \\frac{1}{2} + \\frac{m_i - m_{jk}}{6(\\overline{m_c} - \\overline{m_s})}.\n\\end{aligned}\n\\]\nwith \\(i,j,k \\in \\{1,2,3\\}\\) being mutually different numbers.\nFor the following analyses, we have adjusted our sample so that we meet the assumptions of Li, Turmunkh, and Wakker (2019), namely we have removed all participants who have at least one part with \\(a = 1\\) or violate monotonicity \\((m_i ≤ m_{jk})\\) at least once in part 1 or part 2. In total, this excludes 1200 participants.\nThe structure of the presentation of results follows the discussion in the main part of the paper. We see that on average confirmation messages decrease the probability weight on E1 and E3 and increase the weight given to E2. In contrast, contradiction treatments increase \\(p_1\\) and decrease \\(p_3\\), while the change of \\(p_2\\) is insignificant. These treatment effects on the ambiguity-neutral probabilities thus are consistent with our discussion in section 3.2 on the probability equivalents mi given to the respective events. Separating the different information treatments, we see that the updating of a-neutral probabilities in the confirmation treatments occurs primarily when only the best guess is communicated, while significant updates only results in the contradiction treatments that acknowledge uncertainty. Yet, none of the treatment differences (best guess vs. interval vs. both) are significant. Overall, the analysis of the ambiguity-neutral probabilities is thus in line with the pre-registered analysis of the matching probabilities given to the events Ei which are discussed in the main text and illustrated in Chapter 9.\n\n12.2.1 Figure OE.1\n\ntop   &lt;- plot_bars2(data = subset, response = \"p1\", surprise_sub = NA)\nleft  &lt;- plot_bars2(data = subset, response = \"p1\", surprise_sub = FALSE)\nright &lt;- plot_bars2(data = subset, response = \"p1\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 12.1: A-neutral probability \\(p_1\\) separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: \\(^{*}\\)p&lt;0.10, \\(^{**}\\)p&lt;0.05, \\(^{***}\\)p&lt;0.01, ns: not significant\n\n\n\n\n\n\n12.2.2 Figure OE.2\n\ntop   &lt;- plot_bars2(data = subset, response = \"p2\", surprise_sub = NA)\nleft  &lt;- plot_bars2(data = subset, response = \"p2\", surprise_sub = FALSE)\nright &lt;- plot_bars2(data = subset, response = \"p2\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 12.2: A-neutral probability \\(p_2\\) separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: \\(^{*}\\)p&lt;0.10, \\(^{**}\\)p&lt;0.05, \\(^{***}\\)p&lt;0.01, ns: not significant\n\n\n\n\n\n\n12.2.3 Figure OE.3\n\ntop   &lt;- plot_bars2(data = subset, response = \"p3\", surprise_sub = NA)\nleft  &lt;- plot_bars2(data = subset, response = \"p3\", surprise_sub = FALSE)\nright &lt;- plot_bars2(data = subset, response = \"p3\", surprise_sub = TRUE)\n\n(top / (left | right) & theme(legend.position = \"bottom\")) + plot_layout(guides = \"collect\")\n\n\n\n\nFigure 12.3: A-neutral probability \\(p_3\\) separated by treatments and part 1 and part 2. P-values of Wilcoxon signed-rank test comparing part 1 and 2 directly above the mean values. P-values of Wilcoxon–Mann–Whitney test comparing part 2 of different treatments at the top. Note: \\(^{*}\\)p&lt;0.10, \\(^{**}\\)p&lt;0.05, \\(^{***}\\)p&lt;0.01, ns: not significant\n\n\n\n\n\n\n12.2.4 Table OE.1\n\nols_1 &lt;- lm(formula = p1 ~ surprise + treated + surprise * treated,\n              data = subset)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = subset[, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = p1 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = subset[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = p1 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = subset[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = p1 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = subset[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = p1 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = subset[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = p1 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = subset[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on p1\",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"both x stage2\", \"interval x stage2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE,\n            style = \"qje\")\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on p1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.011)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.020\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n\n\n\n\n\n\n\n\n\n\n-0.014\n\n\n\n\n\n\n\n\n\n\n\n\n-0.026*\n\n\n\n\n\n\n\n\n\n\n\n\n0.049**\n\n\n\n\n\n\n\n\n\n\n\n\n-0.026*\n\n\n\n\n\n\n\n\n\n\n\n\n-0.008\n\n\n\n\n\n\n\n\n\n\n\n\n-0.009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.009)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n0.071***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.075***\n\n\n\n\n\n\n\n\n\n\n\n\n0.059**\n\n\n\n\n\n\n\n\n\n\n\n\n0.082**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.033)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.017\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.037)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n0.003\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n0.302***\n\n\n\n\n\n\n\n\n\n\n\n\n0.313***\n\n\n\n\n\n\n\n\n\n\n\n\n0.305***\n\n\n\n\n\n\n\n\n\n\n\n\n0.313***\n\n\n\n\n\n\n\n\n\n\n\n\n0.293***\n\n\n\n\n\n\n\n\n\n\n\n\n0.302***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.008)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.010)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.011)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN\n\n\n\n\n\n\n\n\n\n\n\n\n610\n\n\n\n\n\n\n\n\n\n\n\n\n298\n\n\n\n\n\n\n\n\n\n\n\n\n312\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n226\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.074\n\n\n\n\n\n\n\n\n\n\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n0.066\n\n\n\n\n\n\n\n\n\n\n\n\n0.050\n\n\n\n\n\n\n\n\n\n\n\n\n0.082\n\n\n\n\n\n\n\n\n\n\n\n\n0.100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.070\n\n\n\n\n\n\n\n\n\n\n\n\n-0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.050\n\n\n\n\n\n\n\n\n\n\n\n\n0.035\n\n\n\n\n\n\n\n\n\n\n\n\n0.069\n\n\n\n\n\n\n\n\n\n\n\n\n0.086\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n0.111\n\n\n\n\n\n\n\n\n\n\n\n\n0.105\n\n\n\n\n\n\n\n\n\n\n\n\n0.116\n\n\n\n\n\n\n\n\n\n\n\n\n0.107\n\n\n\n\n\n\n\n\n\n\n\n\n0.111\n\n\n\n\n\n\n\n\n\n\n\n\n0.114\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n16.194***\n\n\n\n\n\n\n\n\n\n\n\n\n0.474\n\n\n\n\n\n\n\n\n\n\n\n\n4.299***\n\n\n\n\n\n\n\n\n\n\n\n\n3.289**\n\n\n\n\n\n\n\n\n\n\n\n\n6.577***\n\n\n\n\n\n\n\n\n\n\n\n\n6.971***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\n\n\n\n\n\n\n\n\n***Significant at the 1 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Significant at the 5 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Significant at the 10 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.2.5 Table OE.2\n\nols_1 &lt;- lm(formula = p2 ~ surprise + treated + surprise * treated,\n              data = subset)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = subset[, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = p2 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = subset[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = p2 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = subset[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = p2 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = subset[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = p2 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = subset[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = p2 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = subset[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on p2\",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"both x stage2\", \"interval x stage2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE,\n            style = \"qje\")\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-0.018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n-0.049**\n\n\n\n\n\n\n\n\n\n\n\n\n-0.013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.012\n\n\n\n\n\n\n\n\n\n\n\n\n-0.033\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.024)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.038\n\n\n\n\n\n\n\n\n\n\n\n\n-0.019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n\n\n\n\n\n\n\n\n\n\n0.029**\n\n\n\n\n\n\n\n\n\n\n\n\n0.043*\n\n\n\n\n\n\n\n\n\n\n\n\n-0.026\n\n\n\n\n\n\n\n\n\n\n\n\n0.043*\n\n\n\n\n\n\n\n\n\n\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n0.031\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.019)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-0.048***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.068**\n\n\n\n\n\n\n\n\n\n\n\n\n-0.032\n\n\n\n\n\n\n\n\n\n\n\n\n-0.045*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.011\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.030)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.029\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n0.367***\n\n\n\n\n\n\n\n\n\n\n\n\n0.357***\n\n\n\n\n\n\n\n\n\n\n\n\n0.366***\n\n\n\n\n\n\n\n\n\n\n\n\n0.357***\n\n\n\n\n\n\n\n\n\n\n\n\n0.395***\n\n\n\n\n\n\n\n\n\n\n\n\n0.345***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.011)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN\n\n\n\n\n\n\n\n\n\n\n\n\n610\n\n\n\n\n\n\n\n\n\n\n\n\n298\n\n\n\n\n\n\n\n\n\n\n\n\n312\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n226\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.039\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n0.029\n\n\n\n\n\n\n\n\n\n\n\n\n0.030\n\n\n\n\n\n\n\n\n\n\n\n\n0.070\n\n\n\n\n\n\n\n\n\n\n\n\n0.035\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.034\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n0.013\n\n\n\n\n\n\n\n\n\n\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n0.057\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n0.122\n\n\n\n\n\n\n\n\n\n\n\n\n0.150\n\n\n\n\n\n\n\n\n\n\n\n\n0.086\n\n\n\n\n\n\n\n\n\n\n\n\n0.126\n\n\n\n\n\n\n\n\n\n\n\n\n0.123\n\n\n\n\n\n\n\n\n\n\n\n\n0.115\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n8.253***\n\n\n\n\n\n\n\n\n\n\n\n\n1.405\n\n\n\n\n\n\n\n\n\n\n\n\n1.796\n\n\n\n\n\n\n\n\n\n\n\n\n1.913\n\n\n\n\n\n\n\n\n\n\n\n\n5.550***\n\n\n\n\n\n\n\n\n\n\n\n\n2.241*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\n\n\n\n\n\n\n\n\n***Significant at the 1 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Significant at the 5 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Significant at the 10 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.2.6 Table OE.3\n\nols_1 &lt;- lm(formula = p3 ~ surprise + treated + surprise * treated,\n              data = subset)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = subset[, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = p3 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = subset[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = p3 ~ communication + treated + communication * treated, \n              data = subset,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = subset[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = p3 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = subset[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = p3 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = subset[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = p3 ~ surprise + treated + surprise * treated, \n              data = subset,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = subset[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on p3\",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"part2\", \"contradiction x stage 2\", \"both x stage2\", \"interval x stage2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE,\n            style = \"qje\")\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on p3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.0004\n\n\n\n\n\n\n\n\n\n\n\n\n0.025\n\n\n\n\n\n\n\n\n\n\n\n\n-0.002\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.010)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n0.022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.018\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.017)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart2\n\n\n\n\n\n\n\n\n\n\n\n\n-0.015*\n\n\n\n\n\n\n\n\n\n\n\n\n-0.016\n\n\n\n\n\n\n\n\n\n\n\n\n-0.023\n\n\n\n\n\n\n\n\n\n\n\n\n-0.016\n\n\n\n\n\n\n\n\n\n\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n-0.022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.008)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.018)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.015)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-0.023*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n-0.027\n\n\n\n\n\n\n\n\n\n\n\n\n-0.037\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.014)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n-0.036\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.028)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n-0.011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.021)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.025)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n0.331***\n\n\n\n\n\n\n\n\n\n\n\n\n0.329***\n\n\n\n\n\n\n\n\n\n\n\n\n0.330***\n\n\n\n\n\n\n\n\n\n\n\n\n0.329***\n\n\n\n\n\n\n\n\n\n\n\n\n0.311***\n\n\n\n\n\n\n\n\n\n\n\n\n0.353***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.007)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.012)\n\n\n\n\n\n\n\n\n\n\n\n\n(0.013)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN\n\n\n\n\n\n\n\n\n\n\n\n\n610\n\n\n\n\n\n\n\n\n\n\n\n\n298\n\n\n\n\n\n\n\n\n\n\n\n\n312\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n226\n\n\n\n\n\n\n\n\n\n\n\n\n192\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.023\n\n\n\n\n\n\n\n\n\n\n\n\n0.029\n\n\n\n\n\n\n\n\n\n\n\n\n0.045\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.020\n\n\n\n\n\n\n\n\n\n\n\n\n0.064\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.030\n\n\n\n\n\n\n\n\n\n\n\n\n-0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n0.049\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n0.094\n\n\n\n\n\n\n\n\n\n\n\n\n0.094\n\n\n\n\n\n\n\n\n\n\n\n\n0.094\n\n\n\n\n\n\n\n\n\n\n\n\n0.092\n\n\n\n\n\n\n\n\n\n\n\n\n0.096\n\n\n\n\n\n\n\n\n\n\n\n\n0.094\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n4.832***\n\n\n\n\n\n\n\n\n\n\n\n\n1.740\n\n\n\n\n\n\n\n\n\n\n\n\n2.902**\n\n\n\n\n\n\n\n\n\n\n\n\n0.740\n\n\n\n\n\n\n\n\n\n\n\n\n1.512\n\n\n\n\n\n\n\n\n\n\n\n\n4.304***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\n\n\n\n\n\n\n\n\n***Significant at the 1 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Significant at the 5 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Significant at the 10 percent level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.2.7 Table OE.4\n\nols_6_1 &lt;- lm(formula = euclidian_distance ~ surprise, \n            data = wide_subset)\nse_6_1  &lt;- coeftest(ols_6_1, vcov = vcovHC(ols_6_1, type = \"HC1\"))\n\nols_6_2 &lt;- lm(formula = euclidian_distance ~ communication, \n            data = wide_subset,\n            subset = (surprise == FALSE))\nse_6_2  &lt;- coeftest(ols_6_2, vcov = vcovHC(ols_6_2, type = \"HC1\"))\n\nols_6_3 &lt;- lm(formula = euclidian_distance ~ communication, \n            data = wide_subset,\n            subset = (surprise == TRUE))\nse_6_3  &lt;- coeftest(ols_6_3, vcov = vcovHC(ols_6_3, type = \"HC1\"))\n\nols_6_4 &lt;- lm(formula = euclidian_distance ~ surprise, \n            data = wide_subset,\n            subset = (communication == \"point\"))\nse_6_4  &lt;- coeftest(ols_6_4, vcov = vcovHC(ols_6_4, type = \"HC1\"))\n\nols_6_5 &lt;- lm(formula = euclidian_distance ~ surprise, \n            data = wide_subset,\n            subset = (communication == \"interval\"))\nse_6_5  &lt;- coeftest(ols_6_5, vcov = vcovHC(ols_6_5, type = \"HC1\"))\n\nols_6_6 &lt;- lm(formula = euclidian_distance ~ surprise, \n            data = wide_subset,\n            subset = (communication == \"both\"))\nse_6_6  &lt;- coeftest(ols_6_6, vcov = vcovHC(ols_6_6, type = \"HC1\"))\n\nse_6 &lt;- list(se_6_1[,2], se_6_2[,2], se_6_3[,2], se_6_4[,2], se_6_5[,2], se_6_6[,2])\np_6  &lt;- list(se_6_1[,4], se_6_2[,4], se_6_3[,4], se_6_4[,4], se_6_5[,4], se_6_6[,4])\n\nstargazer(ols_6_1, ols_6_2, ols_6_3, ols_6_4, ols_6_5, ols_6_6, \n          align = TRUE, \n          se = se_6,\n          p = p_6,   \n          title = \"Linear regressions: Treatment effects on Euclidian distance between vector of matching probabilities in part 1 vs. part 2\",\n          model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\",  \"Constant\"),\n          font.size = \"scriptsize\",\n          type = \"html\", \n          df = FALSE,\n          style = \"qje\")\n\n\n\nLinear regressions: Treatment effects on Euclidian distance between vector of matching probabilities in part 1 vs. part 2\n\n\n\n\n\n\n\n\n\neuclidian_distance\n\n\n\n\n\n\nfull\n\n\nconfirmation\n\n\ncontradiction\n\n\npoint\n\n\ninterval\n\n\nboth\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\ncontradiction\n\n\n0.021\n\n\n\n\n\n\n0.008\n\n\n0.016\n\n\n0.040\n\n\n\n\n\n\n(0.020)\n\n\n\n\n\n\n(0.037)\n\n\n(0.031)\n\n\n(0.038)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n0.001\n\n\n0.033\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.032)\n\n\n(0.042)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n-0.0003\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.032)\n\n\n(0.036)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.144***\n\n\n0.143***\n\n\n0.152***\n\n\n0.143***\n\n\n0.143***\n\n\n0.145***\n\n\n\n\n\n\n(0.012)\n\n\n(0.024)\n\n\n(0.027)\n\n\n(0.024)\n\n\n(0.021)\n\n\n(0.020)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN\n\n\n305\n\n\n149\n\n\n156\n\n\n96\n\n\n113\n\n\n96\n\n\n\n\nR2\n\n\n0.003\n\n\n0.00003\n\n\n0.005\n\n\n0.001\n\n\n0.002\n\n\n0.012\n\n\n\n\nAdjusted R2\n\n\n0.0002\n\n\n-0.014\n\n\n-0.008\n\n\n-0.010\n\n\n-0.007\n\n\n0.001\n\n\n\n\nResidual Std. Error\n\n\n0.176\n\n\n0.154\n\n\n0.196\n\n\n0.180\n\n\n0.167\n\n\n0.185\n\n\n\n\nF Statistic\n\n\n1.047\n\n\n0.002\n\n\n0.369\n\n\n0.052\n\n\n0.251\n\n\n1.098\n\n\n\n\n\n\n\n\nNotes:\n\n\n***Significant at the 1 percent level.\n\n\n\n\n\n\n**Significant at the 5 percent level.\n\n\n\n\n\n\n*Significant at the 10 percent level.\n\n\n\n\n\n\n12.2.8 Figure OE.4"
  },
  {
    "objectID": "04-appendix-A.html#setup",
    "href": "04-appendix-A.html#setup",
    "title": "4  Appendix A",
    "section": "4.1 Setup",
    "text": "4.1 Setup\n\n4.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n  install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"gt\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n4.1.2 Read Data\n\ndata &lt;- readRDS(file=\"../data/processed/full.Rda\")\n\n\nvars &lt;- str_subset(string = names(data), pattern = \"^.{1,4}$\", negate = TRUE)\ncovariates &lt;- data[stage == 1, ..vars]"
  },
  {
    "objectID": "05-appendix-B.html#setup",
    "href": "05-appendix-B.html#setup",
    "title": "5  Appendix B",
    "section": "5.1 Setup",
    "text": "5.1 Setup\n\n5.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\",\n          \"lmtest\", \"sandwich\", \"stargazer\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2024-08-01\")\n\nrm(pkgs)\n\n\n\n5.1.2 Read Data\n\ndata      &lt;- readRDS(file=\"../data/processed/full.Rda\")\ntimeSpent &lt;- data.table::fread(file = \"../data/raw/PageTimes-2021-09-15.csv\")\nraw       &lt;- data.table::fread(file=\"../data/raw/all_apps_wide_2021-09-15.csv\")"
  },
  {
    "objectID": "05-appendix-B.html#table-b.1",
    "href": "05-appendix-B.html#table-b.1",
    "title": "5  Appendix B",
    "section": "5.2 Table B.1",
    "text": "5.2 Table B.1\n\nols_1 &lt;- lm(formula = E1 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E1 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E1 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E1 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E1 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E1 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E1\",\n            dep.var.caption = \"Dependent variable: E1\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-0.962\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.492\n\n\n\n\n\n\n\n\n\n\n\n\n0.951\n\n\n\n\n\n\n\n\n\n\n\n\n-2.435\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.080)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.760)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.993)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.855)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.430\n\n\n\n\n\n\n\n\n\n\n\n\n1.487\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.759)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.856)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.331\n\n\n\n\n\n\n\n\n\n\n\n\n3.773**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.836)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.923)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-1.036\n\n\n\n\n\n\n\n\n\n\n\n\n0.955\n\n\n\n\n\n\n\n\n\n\n\n\n7.468***\n\n\n\n\n\n\n\n\n\n\n\n\n0.955\n\n\n\n\n\n\n\n\n\n\n\n\n-1.634\n\n\n\n\n\n\n\n\n\n\n\n\n-2.504*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.846)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.500)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.791)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.500)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.498)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.391)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n7.563***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.513***\n\n\n\n\n\n\n\n\n\n\n\n\n4.269*\n\n\n\n\n\n\n\n\n\n\n\n\n12.098***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.315)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.336)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.232)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.251)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-3.459*\n\n\n\n\n\n\n\n\n\n\n\n\n2.126\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.046)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.517)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-2.589\n\n\n\n\n\n\n\n\n\n\n\n\n-4.833**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.120)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.437)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n47.893***\n\n\n\n\n\n\n\n\n\n\n\n\n46.653***\n\n\n\n\n\n\n\n\n\n\n\n\n45.161***\n\n\n\n\n\n\n\n\n\n\n\n\n46.653***\n\n\n\n\n\n\n\n\n\n\n\n\n47.984***\n\n\n\n\n\n\n\n\n\n\n\n\n49.083***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.747)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.193)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.294)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.193)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.395)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.293)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.014\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n0.015\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.028\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.013\n\n\n\n\n\n\n\n\n\n\n\n\n-0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.021\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.003\n\n\n\n\n\n\n\n\n\n\n\n\n0.025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n23.210\n\n\n\n\n\n\n\n\n\n\n\n\n22.727\n\n\n\n\n\n\n\n\n\n\n\n\n23.652\n\n\n\n\n\n\n\n\n\n\n\n\n22.494\n\n\n\n\n\n\n\n\n\n\n\n\n23.624\n\n\n\n\n\n\n\n\n\n\n\n\n23.473\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n13.967***\n\n\n\n\n\n\n\n\n\n\n\n\n0.530\n\n\n\n\n\n\n\n\n\n\n\n\n7.531***\n\n\n\n\n\n\n\n\n\n\n\n\n5.226***\n\n\n\n\n\n\n\n\n\n\n\n\n2.152*\n\n\n\n\n\n\n\n\n\n\n\n\n9.393***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "04-appendix-A.html#table-a.1",
    "href": "04-appendix-A.html#table-a.1",
    "title": "4  Appendix A",
    "section": "4.2 Table A.1",
    "text": "4.2 Table A.1\nUsing the {gt} package, we produce Table A.1 in the steps. First, we create a table containing all the covariates that are treated dummies or continuous variables (see Table 4.1). In a second step, we create Table 4.2 as a separate table.\n\nlong_df &lt;- melt(covariates, \n                id.vars = c(\"surprise\", \"communication\"), \n                measure.vars = c(\"age_18_34\", \"age_35_52\", \"age_53_plus\", \"female\", \"high_education\", \"high_income\", \"married\", \"parentship\", \"high_temperature\", \"high_usage\", \"high_general_risk\", \"high_weather_risk\", \"high_accuracy\", \"high_credibility\", \"temperature\", \"usage\", \"general_risk\", \"weather_risk\", \"accuracy\", \"credibility\"), \n                variable.name = \"Variable\", \n                value.name = \"Value\")\n\npooled_summary &lt;- long_df[, \n                          .(N = sum(!is.na(Value)), \n                            Mean = mean(Value, na.rm = TRUE)), \n                          by = .(Variable)]\n\nsummary_tmp &lt;- long_df[, \n                       .(N = sum(!is.na(Value)), \n                         Mean = mean(Value, na.rm = TRUE)), \n                       by = .(surprise, communication, Variable)]\n\nsummary_table &lt;- merge(pooled_summary, \n                       summary_tmp, \n                       by = \"Variable\", \n                       suffixes = c(\"_pooled\", \"\"))\n\nsummary_table_wide &lt;- dcast(summary_table, \n                            Variable + N_pooled + Mean_pooled ~ surprise + communication, \n                            value.var = c(\"N\", \"Mean\"))\n\nsetcolorder(summary_table_wide, c(\"Variable\", \"N_pooled\", \"Mean_pooled\", \n                                  \"N_FALSE_point\", \"Mean_FALSE_point\", \n                                  \"N_FALSE_both\", \"Mean_FALSE_both\", \n                                  \"N_FALSE_interval\", \"Mean_FALSE_interval\", \n                                  \"N_TRUE_point\", \"Mean_TRUE_point\", \n                                  \"N_TRUE_both\", \"Mean_TRUE_both\", \n                                  \"N_TRUE_interval\", \"Mean_TRUE_interval\"))\n\nsummary_table_wide %&gt;% \n  gt() %&gt;% \n  cols_label(\n    Variable = \"Treatment Variable\",\n    N_pooled = \"N\", Mean_pooled = \"Mean\",\n    N_FALSE_point = \"N\", Mean_FALSE_point = \"Mean\",\n    N_FALSE_both = \"N\", Mean_FALSE_both = \"Mean\",\n    N_FALSE_interval = \"N\", Mean_FALSE_interval = \"Mean\",\n    N_TRUE_point = \"N\", Mean_TRUE_point = \"Mean\",\n    N_TRUE_both = \"N\", Mean_TRUE_both = \"Mean\",\n    N_TRUE_interval = \"N\", Mean_TRUE_interval = \"Mean\"\n  ) %&gt;%\n  tab_spanner(\n    label = \"Pooled\",\n    columns = c(N_pooled, Mean_pooled)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Confirmation\",\n    columns = c(N_FALSE_point, Mean_FALSE_point, N_FALSE_both, Mean_FALSE_both, N_FALSE_interval, Mean_FALSE_interval)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Contradiction\",\n    columns = c(N_TRUE_point, Mean_TRUE_point, N_TRUE_both, Mean_TRUE_both, N_TRUE_interval, Mean_TRUE_interval)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Point\",\n    id = \"conf_point\",\n    columns = c(N_FALSE_point, Mean_FALSE_point),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Both\",\n    id = \"conf_both\",\n    columns = c(N_FALSE_both, Mean_FALSE_both),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Interval\",\n    id = \"conf_interval\",\n    columns = c(N_FALSE_interval, Mean_FALSE_interval),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Point\",\n    id = \"contra_point\",\n    columns = c(N_TRUE_point, Mean_TRUE_point),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Both\",\n    id = \"contra_both\",\n    columns = c(N_TRUE_both, Mean_TRUE_both),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Interval\",\n    id = \"contra_interval\",\n    columns = c(N_TRUE_interval, Mean_TRUE_interval),\n    level = 2\n  ) %&gt;%\n  fmt_number(\n    columns = starts_with(\"Mean\"),\n    decimals = 3\n  ) %&gt;%\n  fmt_number(\n    columns = starts_with(\"N\"),\n    decimals = 0\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = c(Variable)\n  )\n\n\n\n\n\nTable 4.1:  Descriptive statistics (control variables): Mean values per\ntreatment \n  \n    \n      \n      \n        Point\n      \n      \n        Both\n      \n      \n        Interval\n      \n      \n        Point\n      \n      \n        Both\n      \n      \n        Interval\n      \n    \n    \n      Treatment Variable\n      \n        Pooled\n      \n      \n        Confirmation\n      \n      \n        Contradiction\n      \n    \n    \n      N\n      Mean\n      N\n      Mean\n      N\n      Mean\n      N\n      Mean\n      N\n      Mean\n      N\n      Mean\n      N\n      Mean\n    \n  \n  \n    age_18_34\n1,503\n0.335\n255\n0.325\n247\n0.296\n243\n0.309\n251\n0.386\n249\n0.345\n258\n0.345\n    age_35_52\n1,503\n0.306\n255\n0.310\n247\n0.300\n243\n0.313\n251\n0.299\n249\n0.313\n258\n0.302\n    age_53_plus\n1,503\n0.359\n255\n0.365\n247\n0.405\n243\n0.379\n251\n0.315\n249\n0.341\n258\n0.353\n    female\n1,505\n0.490\n255\n0.463\n247\n0.478\n243\n0.444\n252\n0.540\n250\n0.528\n258\n0.484\n    high_education\n1,505\n0.618\n255\n0.616\n247\n0.575\n243\n0.687\n252\n0.643\n250\n0.612\n258\n0.578\n    high_income\n1,363\n0.525\n230\n0.552\n227\n0.498\n220\n0.564\n225\n0.547\n227\n0.471\n234\n0.517\n    married\n1,505\n0.396\n255\n0.427\n247\n0.421\n243\n0.379\n252\n0.389\n250\n0.356\n258\n0.403\n    parentship\n1,505\n0.429\n255\n0.400\n247\n0.482\n243\n0.395\n252\n0.440\n250\n0.404\n258\n0.450\n    high_temperature\n1,505\n0.591\n255\n0.557\n247\n0.543\n243\n0.613\n252\n0.575\n250\n0.668\n258\n0.589\n    high_usage\n1,505\n0.511\n255\n0.518\n247\n0.526\n243\n0.494\n252\n0.548\n250\n0.516\n258\n0.465\n    high_general_risk\n1,505\n0.540\n255\n0.561\n247\n0.514\n243\n0.506\n252\n0.512\n250\n0.552\n258\n0.589\n    high_weather_risk\n1,505\n0.633\n255\n0.600\n247\n0.587\n243\n0.588\n252\n0.679\n250\n0.660\n258\n0.678\n    high_accuracy\n1,505\n0.786\n255\n0.800\n247\n0.810\n243\n0.819\n252\n0.698\n250\n0.836\n258\n0.756\n    high_credibility\n1,505\n0.503\n255\n0.490\n247\n0.615\n243\n0.560\n252\n0.369\n250\n0.504\n258\n0.484\n    temperature\n1,505\n20.051\n255\n19.906\n247\n19.526\n243\n20.267\n252\n20.079\n250\n20.468\n258\n20.062\n    usage\n1,505\n3.347\n255\n3.408\n247\n3.348\n243\n3.350\n252\n3.393\n250\n3.308\n258\n3.275\n    general_risk\n1,505\n4.193\n255\n4.290\n247\n3.988\n243\n4.012\n252\n4.048\n250\n4.396\n258\n4.407\n    weather_risk\n1,505\n5.260\n255\n5.122\n247\n4.935\n243\n4.967\n252\n5.433\n250\n5.496\n258\n5.585\n    accuracy\n1,505\n2.241\n255\n2.306\n247\n2.405\n243\n2.366\n252\n1.992\n250\n2.308\n258\n2.081\n    credibility\n1,505\n2.378\n255\n2.380\n247\n2.559\n243\n2.498\n252\n2.056\n250\n2.404\n258\n2.380\n  \n  \n  \n\n\n\n\n\n\n# Calculate total observations for each treatment arm\ntotal_obs &lt;- covariates[, .(n = .N), by = .(surprise, communication)]\n\n# Create a summary of the comprehension variable\ncomprehension_summary &lt;- covariates[, .(n = .N), by = .(surprise, communication, comprehension)]\ncomprehension_summary[, percentage := n / sum(n) * 100, by = .(surprise, communication)]\n\n# Reshape the data to wide format\ncomprehension_wide &lt;- dcast(comprehension_summary, \n                            comprehension ~ surprise + communication, \n                            value.var = c(\"n\", \"percentage\"))\n\n# Calculate pooled values\ncomprehension_wide[, n_pooled := rowSums(.SD), .SDcols = patterns(\"^n_\")]\ncomprehension_wide[, percentage_pooled := n_pooled / sum(n_pooled) * 100]\n\n# Create a row for total observations\ntotal_row &lt;- data.table(\n  comprehension = \"Total\",\n  n_pooled = sum(total_obs$n),\n  percentage_pooled = NA_real_,  # Set to NA to hide the percentage\n  n_FALSE_point = total_obs[surprise == FALSE & communication == \"point\", n],\n  percentage_FALSE_point = NA_real_,  # Set to NA to hide the percentage\n  n_FALSE_both = total_obs[surprise == FALSE & communication == \"both\", n],\n  percentage_FALSE_both = NA_real_,  # Set to NA to hide the percentage\n  n_FALSE_interval = total_obs[surprise == FALSE & communication == \"interval\", n],\n  percentage_FALSE_interval = NA_real_,  # Set to NA to hide the percentage\n  n_TRUE_point = total_obs[surprise == TRUE & communication == \"point\", n],\n  percentage_TRUE_point = NA_real_,  # Set to NA to hide the percentage\n  n_TRUE_both = total_obs[surprise == TRUE & communication == \"both\", n],\n  percentage_TRUE_both = NA_real_,  # Set to NA to hide the percentage\n  n_TRUE_interval = total_obs[surprise == TRUE & communication == \"interval\", n],\n  percentage_TRUE_interval = NA_real_  # Set to NA to hide the percentage\n)\n\n# Combine total row with comprehension data\ncomprehension_wide &lt;- rbindlist(list(total_row, comprehension_wide), fill = TRUE)\n\n# Create the table\ngt_table &lt;- comprehension_wide %&gt;%\n  gt() %&gt;%\n  cols_label(\n    comprehension = \"comprehension\",\n    n_pooled = \"N\", percentage_pooled = \"%\",\n    n_FALSE_point = \"N\", percentage_FALSE_point = \"%\",\n    n_FALSE_both = \"N\", percentage_FALSE_both = \"%\",\n    n_FALSE_interval = \"N\", percentage_FALSE_interval = \"%\",\n    n_TRUE_point = \"N\", percentage_TRUE_point = \"%\",\n    n_TRUE_both = \"N\", percentage_TRUE_both = \"%\",\n    n_TRUE_interval = \"N\", percentage_TRUE_interval = \"%\"\n  ) %&gt;%\n  tab_spanner(\n    label = \"Pooled\",\n    columns = c(n_pooled, percentage_pooled)\n  ) %&gt;%\n  tab_spanner(\n    label = \"Confirmation\",\n    columns = c(n_FALSE_point, percentage_FALSE_point, n_FALSE_both, percentage_FALSE_both, n_FALSE_interval, percentage_FALSE_interval),\n    level = 1\n  ) %&gt;%\n  tab_spanner(\n    label = \"Contradiction\",\n    columns = c(n_TRUE_point, percentage_TRUE_point, n_TRUE_both, percentage_TRUE_both, n_TRUE_interval, percentage_TRUE_interval),\n    level = 1\n  ) %&gt;%\n  tab_spanner(\n    label = \"Point\",\n    id = \"conf_point\",\n    columns = c(n_FALSE_point, percentage_FALSE_point),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Both\",\n    id = \"conf_both\",\n    columns = c(n_FALSE_both, percentage_FALSE_both),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Interval\",\n    id = \"conf_interval\",\n    columns = c(n_FALSE_interval, percentage_FALSE_interval),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Point\",\n    id = \"contra_point\",\n    columns = c(n_TRUE_point, percentage_TRUE_point),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Both\",\n    id = \"contra_both\",\n    columns = c(n_TRUE_both, percentage_TRUE_both),\n    level = 2\n  ) %&gt;%\n  tab_spanner(\n    label = \"Interval\",\n    id = \"contra_interval\",\n    columns = c(n_TRUE_interval, percentage_TRUE_interval),\n    level = 2\n  ) %&gt;%\n  fmt_number(\n    columns = contains(\"percentage\"),\n    decimals = 1,\n    suffix = \"%\"\n  ) %&gt;%\n  fmt_number(\n    columns = starts_with(\"n\"),\n    decimals = 0\n  ) %&gt;%\n  cols_align(\n    align = \"left\",\n    columns = c(comprehension)\n  ) %&gt;%\n  tab_style(\n    style = cell_text(weight = \"bold\"),\n    locations = cells_body(\n      rows = 1\n    )\n  ) %&gt;%\n  fmt_missing(columns = everything(), missing_text = \"\")  # This will replace NA with an empty string\n\n# Display the table\ngt_table\n\n\n\n\n\nTable 4.2:  Descriptive statistics (control variables): Mean values per\ntreatment \n  \n    \n      \n      \n        Point\n      \n      \n        Both\n      \n      \n        Interval\n      \n      \n        Point\n      \n      \n        Both\n      \n      \n        Interval\n      \n    \n    \n      comprehension\n      \n        Pooled\n      \n      \n        Confirmation\n      \n      \n        Contradiction\n      \n    \n    \n      N\n      %\n      N\n      %\n      N\n      %\n      N\n      %\n      N\n      %\n      N\n      %\n      N\n      %\n    \n  \n  \n    Total\n1,505\n\n255\n\n247\n\n243\n\n252\n\n250\n\n258\n\n    no\n32\n2.1\n5\n2.0\n5\n2.0\n8\n3.3\n3\n1.2\n5\n2.0\n6\n2.3\n    rather not\n254\n16.9\n44\n17.3\n40\n16.2\n38\n15.6\n50\n19.8\n43\n17.2\n39\n15.1\n    rather yes\n739\n49.1\n132\n51.8\n114\n46.2\n125\n51.4\n112\n44.4\n131\n52.4\n125\n48.4\n    yes\n480\n31.9\n74\n29.0\n88\n35.6\n72\n29.6\n87\n34.5\n71\n28.4\n88\n34.1"
  },
  {
    "objectID": "05-appendix-B.html#table-b.2",
    "href": "05-appendix-B.html#table-b.2",
    "title": "5  Appendix B",
    "section": "5.3 Table B.2",
    "text": "5.3 Table B.2\n\nols_1 &lt;- lm(formula = E2 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E2 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E2 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E2 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E2 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E2 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E2\",\n            dep.var.caption = \"Dependent variable: E2\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-1.235\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.497\n\n\n\n\n\n\n\n\n\n\n\n\n-1.578\n\n\n\n\n\n\n\n\n\n\n\n\n-0.612\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.072)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.779)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.943)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.852)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.558\n\n\n\n\n\n\n\n\n\n\n\n\n2.443\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.806)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.825)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.174\n\n\n\n\n\n\n\n\n\n\n\n\n0.092\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.867)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.858)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n3.535***\n\n\n\n\n\n\n\n\n\n\n\n\n4.227***\n\n\n\n\n\n\n\n\n\n\n\n\n-3.103**\n\n\n\n\n\n\n\n\n\n\n\n\n4.227***\n\n\n\n\n\n\n\n\n\n\n\n\n2.998**\n\n\n\n\n\n\n\n\n\n\n\n\n3.348**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.782)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.159)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.407)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.159)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.468)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.433)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-5.636***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-7.331***\n\n\n\n\n\n\n\n\n\n\n\n\n-3.812*\n\n\n\n\n\n\n\n\n\n\n\n\n-5.768***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.125)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.824)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.977)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.059)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.879\n\n\n\n\n\n\n\n\n\n\n\n\n0.683\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.843)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.041)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.230\n\n\n\n\n\n\n\n\n\n\n\n\n2.289\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.871)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.932)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n50.681***\n\n\n\n\n\n\n\n\n\n\n\n\n50.108***\n\n\n\n\n\n\n\n\n\n\n\n\n48.611***\n\n\n\n\n\n\n\n\n\n\n\n\n50.108***\n\n\n\n\n\n\n\n\n\n\n\n\n50.282***\n\n\n\n\n\n\n\n\n\n\n\n\n51.666***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.757)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.250)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.265)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.250)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.387)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.304)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.013\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.023\n\n\n\n\n\n\n\n\n\n\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.020\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n21.997\n\n\n\n\n\n\n\n\n\n\n\n\n22.066\n\n\n\n\n\n\n\n\n\n\n\n\n21.941\n\n\n\n\n\n\n\n\n\n\n\n\n20.890\n\n\n\n\n\n\n\n\n\n\n\n\n22.813\n\n\n\n\n\n\n\n\n\n\n\n\n22.276\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n12.879***\n\n\n\n\n\n\n\n\n\n\n\n\n2.214*\n\n\n\n\n\n\n\n\n\n\n\n\n1.655\n\n\n\n\n\n\n\n\n\n\n\n\n7.827***\n\n\n\n\n\n\n\n\n\n\n\n\n2.700**\n\n\n\n\n\n\n\n\n\n\n\n\n3.462**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "05-appendix-B.html#table-b.3",
    "href": "05-appendix-B.html#table-b.3",
    "title": "5  Appendix B",
    "section": "5.4 Table B.3",
    "text": "5.4 Table B.3\n\nols_1 &lt;- lm(formula = E3 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E3 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E3 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E3 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E3 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E3 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E3\",\n            dep.var.caption = \"Dependent variable: E3\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-0.317\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.231\n\n\n\n\n\n\n\n\n\n\n\n\n0.356\n\n\n\n\n\n\n\n\n\n\n\n\n-2.623\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.049)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.814)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.864)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.767)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.813***\n\n\n\n\n\n\n\n\n\n\n\n\n0.958\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.752)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.828)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.199\n\n\n\n\n\n\n\n\n\n\n\n\n1.323\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.787)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.889)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n0.148\n\n\n\n\n\n\n\n\n\n\n\n\n2.161\n\n\n\n\n\n\n\n\n\n\n\n\n-5.425***\n\n\n\n\n\n\n\n\n\n\n\n\n2.161\n\n\n\n\n\n\n\n\n\n\n\n\n-0.006\n\n\n\n\n\n\n\n\n\n\n\n\n-1.779\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.818)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.477)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.635)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.477)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.283)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.469)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-3.721***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-7.585***\n\n\n\n\n\n\n\n\n\n\n\n\n-2.558\n\n\n\n\n\n\n\n\n\n\n\n\n-0.971\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.217)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.204)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.972)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.136)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-3.940*\n\n\n\n\n\n\n\n\n\n\n\n\n2.675\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.083)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.253)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-2.167\n\n\n\n\n\n\n\n\n\n\n\n\n2.861\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.956)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.217)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n48.591***\n\n\n\n\n\n\n\n\n\n\n\n\n46.278***\n\n\n\n\n\n\n\n\n\n\n\n\n47.510***\n\n\n\n\n\n\n\n\n\n\n\n\n46.278***\n\n\n\n\n\n\n\n\n\n\n\n\n48.477***\n\n\n\n\n\n\n\n\n\n\n\n\n51.091***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.733)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.204)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.357)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.204)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.321)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.274)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n-0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n22.475\n\n\n\n\n\n\n\n\n\n\n\n\n21.461\n\n\n\n\n\n\n\n\n\n\n\n\n23.399\n\n\n\n\n\n\n\n\n\n\n\n\n22.160\n\n\n\n\n\n\n\n\n\n\n\n\n22.847\n\n\n\n\n\n\n\n\n\n\n\n\n22.373\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n5.563***\n\n\n\n\n\n\n\n\n\n\n\n\n1.320\n\n\n\n\n\n\n\n\n\n\n\n\n2.815**\n\n\n\n\n\n\n\n\n\n\n\n\n4.050***\n\n\n\n\n\n\n\n\n\n\n\n\n0.678\n\n\n\n\n\n\n\n\n\n\n\n\n2.489*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "05-appendix-B.html#table-b.4",
    "href": "05-appendix-B.html#table-b.4",
    "title": "5  Appendix B",
    "section": "5.5 Table B.4",
    "text": "5.5 Table B.4\n\nols_1 &lt;- lm(formula = E12 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E12 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E12 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E12 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E12 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E12 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E12\",\n            dep.var.caption = \"Dependent variable: E12\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n-0.453\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.446\n\n\n\n\n\n\n\n\n\n\n\n\n-1.087\n\n\n\n\n\n\n\n\n\n\n\n\n-0.776\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.031)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.772)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.754)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.838)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.672\n\n\n\n\n\n\n\n\n\n\n\n\n0.451\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.760)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.850)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.072\n\n\n\n\n\n\n\n\n\n\n\n\n0.539\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.743)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.783)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n1.817**\n\n\n\n\n\n\n\n\n\n\n\n\n3.090**\n\n\n\n\n\n\n\n\n\n\n\n\n4.460***\n\n\n\n\n\n\n\n\n\n\n\n\n3.090**\n\n\n\n\n\n\n\n\n\n\n\n\n-0.401\n\n\n\n\n\n\n\n\n\n\n\n\n2.684*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.828)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.365)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.611)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.365)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.499)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.440)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n3.950***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.370\n\n\n\n\n\n\n\n\n\n\n\n\n5.012**\n\n\n\n\n\n\n\n\n\n\n\n\n5.592***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.198)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.112)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.050)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.065)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-0.406\n\n\n\n\n\n\n\n\n\n\n\n\n3.816*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.984)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.187)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-3.491*\n\n\n\n\n\n\n\n\n\n\n\n\n0.150\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.027)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.134)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n58.358***\n\n\n\n\n\n\n\n\n\n\n\n\n57.127***\n\n\n\n\n\n\n\n\n\n\n\n\n57.573***\n\n\n\n\n\n\n\n\n\n\n\n\n57.127***\n\n\n\n\n\n\n\n\n\n\n\n\n59.200***\n\n\n\n\n\n\n\n\n\n\n\n\n58.800***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.716)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.230)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.276)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.230)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.234)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.258)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n0.008\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n0.021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.015\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n0.018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n22.155\n\n\n\n\n\n\n\n\n\n\n\n\n21.169\n\n\n\n\n\n\n\n\n\n\n\n\n23.078\n\n\n\n\n\n\n\n\n\n\n\n\n22.444\n\n\n\n\n\n\n\n\n\n\n\n\n21.919\n\n\n\n\n\n\n\n\n\n\n\n\n22.090\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n10.599***\n\n\n\n\n\n\n\n\n\n\n\n\n1.214\n\n\n\n\n\n\n\n\n\n\n\n\n5.751***\n\n\n\n\n\n\n\n\n\n\n\n\n2.679**\n\n\n\n\n\n\n\n\n\n\n\n\n2.266*\n\n\n\n\n\n\n\n\n\n\n\n\n7.149***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "05-appendix-B.html#table-b.5",
    "href": "05-appendix-B.html#table-b.5",
    "title": "5  Appendix B",
    "section": "5.6 Table B.5",
    "text": "5.6 Table B.5\n\nols_1 &lt;- lm(formula = E13 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E13 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E13 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E13 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E13 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E13 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E13\",\n            dep.var.caption = \"Dependent variable: E13\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n0.922\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-2.686\n\n\n\n\n\n\n\n\n\n\n\n\n4.258**\n\n\n\n\n\n\n\n\n\n\n\n\n1.173\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.037)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.743)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.846)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.792)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.479\n\n\n\n\n\n\n\n\n\n\n\n\n4.338**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.749)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.786)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.358\n\n\n\n\n\n\n\n\n\n\n\n\n5.586***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.811)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.779)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-1.549*\n\n\n\n\n\n\n\n\n\n\n\n\n-1.333\n\n\n\n\n\n\n\n\n\n\n\n\n4.212***\n\n\n\n\n\n\n\n\n\n\n\n\n-1.333\n\n\n\n\n\n\n\n\n\n\n\n\n0.068\n\n\n\n\n\n\n\n\n\n\n\n\n-3.362**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.873)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.414)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.579)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.414)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.581)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.543)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n3.721***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.546***\n\n\n\n\n\n\n\n\n\n\n\n\n-0.192\n\n\n\n\n\n\n\n\n\n\n\n\n5.848***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.221)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.120)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.054)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.176)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-2.029\n\n\n\n\n\n\n\n\n\n\n\n\n-1.726\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.093)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.201)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.401\n\n\n\n\n\n\n\n\n\n\n\n\n-4.336**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.121)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.052)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n55.130***\n\n\n\n\n\n\n\n\n\n\n\n\n55.414***\n\n\n\n\n\n\n\n\n\n\n\n\n52.728***\n\n\n\n\n\n\n\n\n\n\n\n\n55.414***\n\n\n\n\n\n\n\n\n\n\n\n\n54.056***\n\n\n\n\n\n\n\n\n\n\n\n\n55.893***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.736)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.200)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.264)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.200)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.357)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.273)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n-0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n0.002\n\n\n\n\n\n\n\n\n\n\n\n\n0.006\n\n\n\n\n\n\n\n\n\n\n\n\n0.010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n21.788\n\n\n\n\n\n\n\n\n\n\n\n\n22.070\n\n\n\n\n\n\n\n\n\n\n\n\n21.473\n\n\n\n\n\n\n\n\n\n\n\n\n21.291\n\n\n\n\n\n\n\n\n\n\n\n\n21.762\n\n\n\n\n\n\n\n\n\n\n\n\n22.259\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n5.977***\n\n\n\n\n\n\n\n\n\n\n\n\n0.717\n\n\n\n\n\n\n\n\n\n\n\n\n3.041***\n\n\n\n\n\n\n\n\n\n\n\n\n1.812\n\n\n\n\n\n\n\n\n\n\n\n\n3.054**\n\n\n\n\n\n\n\n\n\n\n\n\n4.266***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "05-appendix-B.html#table-b.6",
    "href": "05-appendix-B.html#table-b.6",
    "title": "5  Appendix B",
    "section": "5.7 Table B.6",
    "text": "5.7 Table B.6\n\nols_1 &lt;- lm(formula = E23 ~ surprise + treated + surprise * treated,\n              data = data)\n  se_1  &lt;- coeftest(x = ols_1, \n                    vcov = vcovCL(ols_1,\n                                  cluster = ~data$participant.label,\n                                  type = \"HC1\"))\n  \n  ols_2 &lt;- lm(formula = E23 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == FALSE))\n  se_2  &lt;- coeftest(x = ols_2, \n                    vcov = vcovCL(ols_2,\n                                  cluster = data[surprise == FALSE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_3 &lt;- lm(formula = E23 ~ communication + treated + communication * treated, \n              data = data,\n              subset = (surprise == TRUE))\n  se_3  &lt;- coeftest(x = ols_3, \n                    vcov = vcovCL(ols_3,\n                                  cluster = data[surprise == TRUE, participant.label],\n                                  type = \"HC1\"))\n  \n  ols_4 &lt;- lm(formula = E23 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"point\"))\n  se_4  &lt;- coeftest(x = ols_4, \n                    vcov = vcovCL(ols_4,\n                                  cluster = data[communication == \"point\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_5 &lt;- lm(formula = E23 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"interval\"))\n  se_5  &lt;- coeftest(x = ols_5, \n                    vcov = vcovCL(ols_5,\n                                  cluster = data[communication == \"interval\", participant.label],\n                                  type = \"HC1\"))\n  \n  ols_6 &lt;- lm(formula = E23 ~ surprise + treated + surprise * treated, \n              data = data,\n              subset = (communication == \"both\"))\n  se_6  &lt;- coeftest(x = ols_6, \n                    vcov = vcovCL(ols_6,\n                                  cluster = data[communication == \"both\", participant.label],\n                                  type = \"HC1\"))\n  \n  \n  \n  se &lt;- list(se_1[,2], se_2[,2], se_3[,2], se_4[,2], se_5[,2], se_6[,2])\n  p  &lt;- list(se_1[,4], se_2[,4], se_3[,4], se_4[,4], se_5[,4], se_6[,4])\n  \n  stargazer(ols_1, ols_2, ols_3, ols_4, ols_5, ols_6, \n            align = TRUE, \n            se = se, \n            p = p,   \n            title = \"Linear regressions: Treatment effects on E23\",\n            dep.var.caption = \"Dependent variable: E23\",\n            dep.var.labels = \" \",\n            model.names = FALSE,\n            column.labels = c(\"full\", \"confirmation\", \"contradiction\", \"point\", \"interval\", \"both\"),\n            covariate.labels = c(\"contradiction\", \"both\", \"interval\", \"stage 2\", \"contradiction x stage 2\", \"interval x stage 2\", \"both x stage 2\", \"Constant\"),\n            font.size = \"scriptsize\",\n            type = \"html\", \n            df = FALSE)\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regressions: Treatment effects on E23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependent variable: E23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfull\n\n\n\n\n\n\n\n\n\n\n\n\nconfirmation\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\npoint\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\n\n\n\n\n\n\n\n\n(2)\n\n\n\n\n\n\n\n\n\n\n\n\n(3)\n\n\n\n\n\n\n\n\n\n\n\n\n(4)\n\n\n\n\n\n\n\n\n\n\n\n\n(5)\n\n\n\n\n\n\n\n\n\n\n\n\n(6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction\n\n\n\n\n\n\n\n\n\n\n\n\n1.513\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.254\n\n\n\n\n\n\n\n\n\n\n\n\n1.193\n\n\n\n\n\n\n\n\n\n\n\n\n3.086\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.154)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.075)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.963)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.959)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.306\n\n\n\n\n\n\n\n\n\n\n\n\n3.139\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.028)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.006)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.722\n\n\n\n\n\n\n\n\n\n\n\n\n1.661\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.047)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.992)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstage 2\n\n\n\n\n\n\n\n\n\n\n\n\n3.099***\n\n\n\n\n\n\n\n\n\n\n\n\n3.308**\n\n\n\n\n\n\n\n\n\n\n\n\n-7.562***\n\n\n\n\n\n\n\n\n\n\n\n\n3.308**\n\n\n\n\n\n\n\n\n\n\n\n\n2.074\n\n\n\n\n\n\n\n\n\n\n\n\n3.893**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.855)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.389)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.812)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.389)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.458)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.597)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontradiction x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n-10.200***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-10.869***\n\n\n\n\n\n\n\n\n\n\n\n\n-7.545***\n\n\n\n\n\n\n\n\n\n\n\n\n-12.211***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(1.326)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.283)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.198)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.417)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterval x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.585\n\n\n\n\n\n\n\n\n\n\n\n\n-0.756\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.116)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.564)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nboth x stage 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-1.234\n\n\n\n\n\n\n\n\n\n\n\n\n2.091\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(2.013)\n\n\n\n\n\n\n\n\n\n\n\n\n(2.447)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n\n\n\n\n\n\n\n\n\n\n59.658***\n\n\n\n\n\n\n\n\n\n\n\n\n59.322***\n\n\n\n\n\n\n\n\n\n\n\n\n59.575***\n\n\n\n\n\n\n\n\n\n\n\n\n59.322***\n\n\n\n\n\n\n\n\n\n\n\n\n60.043***\n\n\n\n\n\n\n\n\n\n\n\n\n59.628***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.829)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.452)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.481)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.453)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.442)\n\n\n\n\n\n\n\n\n\n\n\n\n(1.416)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n\n\n\n\n\n\n\n\n3,010\n\n\n\n\n\n\n\n\n\n\n\n\n1,490\n\n\n\n\n\n\n\n\n\n\n\n\n1,520\n\n\n\n\n\n\n\n\n\n\n\n\n1,014\n\n\n\n\n\n\n\n\n\n\n\n\n1,002\n\n\n\n\n\n\n\n\n\n\n\n\n994\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR2\n\n\n\n\n\n\n\n\n\n\n\n\n0.020\n\n\n\n\n\n\n\n\n\n\n\n\n0.005\n\n\n\n\n\n\n\n\n\n\n\n\n0.027\n\n\n\n\n\n\n\n\n\n\n\n\n0.026\n\n\n\n\n\n\n\n\n\n\n\n\n0.012\n\n\n\n\n\n\n\n\n\n\n\n\n0.024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjusted R2\n\n\n\n\n\n\n\n\n\n\n\n\n0.019\n\n\n\n\n\n\n\n\n\n\n\n\n0.001\n\n\n\n\n\n\n\n\n\n\n\n\n0.023\n\n\n\n\n\n\n\n\n\n\n\n\n0.023\n\n\n\n\n\n\n\n\n\n\n\n\n0.009\n\n\n\n\n\n\n\n\n\n\n\n\n0.021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n\n\n\n\n\n\n\n\n23.195\n\n\n\n\n\n\n\n\n\n\n\n\n23.236\n\n\n\n\n\n\n\n\n\n\n\n\n23.167\n\n\n\n\n\n\n\n\n\n\n\n\n23.966\n\n\n\n\n\n\n\n\n\n\n\n\n22.547\n\n\n\n\n\n\n\n\n\n\n\n\n23.058\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF Statistic\n\n\n\n\n\n\n\n\n\n\n\n\n20.085***\n\n\n\n\n\n\n\n\n\n\n\n\n1.441\n\n\n\n\n\n\n\n\n\n\n\n\n8.284***\n\n\n\n\n\n\n\n\n\n\n\n\n8.939***\n\n\n\n\n\n\n\n\n\n\n\n\n3.966***\n\n\n\n\n\n\n\n\n\n\n\n\n8.016***\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n\n\n\n\n\n\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01"
  },
  {
    "objectID": "06-appendix-C.html#setup",
    "href": "06-appendix-C.html#setup",
    "title": "6  Appendix C",
    "section": "6.1 Setup",
    "text": "6.1 Setup\n\n6.1.1 Install Packages\nWe install the following packages using the groundhog package manager to increase computational reproducibility.\n\noptions(repos = c(CRAN = \"https://cran.r-project.org\")) \n\nif (!requireNamespace(\"groundhog\", quietly = TRUE)) {\n    install.packages(\"groundhog\")\n    library(\"groundhog\")\n}\n\npkgs &lt;- c(\"magrittr\", \"data.table\", \"stringr\", \"Rmisc\", \"ggplot2\")\n\ngroundhog::groundhog.library(pkg = pkgs,\n                             date = \"2023-09-25\")\n\n\n\n6.1.2 Read Data\n\ndata      &lt;- readRDS(file=\"../data/processed/full.Rda\")\ntimeSpent &lt;- data.table::fread(file = \"../data/raw/PageTimes-2021-09-15.csv\")\nraw       &lt;- data.table::fread(file=\"../data/raw/all_apps_wide_2021-09-15.csv\")\n\n\n\n6.1.3 Design\nWe define some design features in the following:\n\ncolors &lt;- c(\"#F3B05C\", \"#1E4A75\", \"#65B5C0\", \"#AD5E21\")\n\nlayout &lt;- theme(panel.background = element_rect(fill = \"white\"),\n                legend.key = element_rect(fill = \"white\"),\n                panel.grid.major.y = element_line(colour = \"grey\", \n                                                  linewidth = 0.25),\n                axis.ticks.y = element_blank(),\n                panel.grid.major.x = element_blank(),\n                axis.line.x.bottom = element_line(colour = \"#000000\", \n                                                  linewidth = 0.5),\n                axis.line.y.left = element_blank(),\n                plot.title = element_text(size = rel(1))\n)\n\nWe examine the heterogeneous effects by estimating a triple interaction effect regression:\n\\[\n\\begin{aligned}\ny_{it} = &\\ \\alpha_{\\text{baseline}} + \\sum_{\\text{treat}} \\alpha_{\\text{treat}} \\text{treat}_i + \\beta_{\\text{baseline}} \\text{part2}_t + \\sum_{\\text{treat}} \\beta_{\\text{treat}} \\text{treat}_i \\times \\text{part2}_t \\\\\n&\\ + \\theta_{\\text{baseline}} (D_i \\times \\text{part2}_t) + \\sum_{\\text{treat}} \\theta_{\\text{treat}} (D_i \\times \\text{treat}_i \\times \\text{part2}_t) \\\\\n&\\ + \\delta_{\\text{baseline}} D_i + \\sum_{\\text{treat}} \\delta_{\\text{treat}} (D_i \\times \\text{treat}_i) + \\gamma X_i + \\epsilon_{it}\n\\end{aligned}\n\\]\nThe figure C.1a displays the estimators \\(\\beta_{treat}\\) and \\(\\theta_{treat}\\). The triple interaction effects \\(\\theta_{treat}\\) are labelled with education DDD, temperature DDD, forecast usage DDD, credible DDD, accurate DDD, and female DDD in this case. The double interaction effects \\(\\beta_{treat}\\) are labelled with lower education, lower temperature, less forecast usage, less credible, less accurate, and not female in this case. For example, to determine the total treatment effect for female on \\(b\\) , one must add the estimators \\(\\beta_{treat}\\) (\\(b\\) (not female)) and \\(\\delta_{treat}\\) (\\(b\\) (female DDD)). The same principle can be applied to the other two figures.\nIn figure C.1a, we pool across the different information treatments (interval, best guess, both) and only consider the heterogeneous effect of contradiction vs. confirmation. treat refers to contradiction while confirmation is used as the baseline.\nIn figure C.1b and C.1c, we test the heterogeneous effects of the different information treatments (interval, best guess, both) separately for confirmation and contradiction treatment arms. The best guess information treatment serves as the baseline and treat refers to the information treatments interval or both."
  },
  {
    "objectID": "01-pre-processing.html#references",
    "href": "01-pre-processing.html#references",
    "title": "1  Pre-Processing",
    "section": "1.11 References",
    "text": "1.11 References\n\n\n\n\nAnantanasuwong, Kanin, Roy Kouwenberg, Olivia S Mitchell, and Kim Peijnenberg. 2019. “Ambiguity Attitudes about Investments: Evidence from the Field.” Working Paper 25561. Working Paper Series. National Bureau of Economic Research. https://doi.org/10.3386/w25561.\n\n\nBaillon, Aurélien, Zhenxing Huang, Asli Selim, and Peter P. Wakker. 2018. “Measuring Ambiguity Attitudes for All (Natural) Events.” Econometrica 86 (5): 1839–58. https://doi.org/10.3982/ECTA14370.\n\n\nChen, Daniel L., Martin Schonger, and Chris Wickens. 2016. “oTree-an Open-Source Platform for Laboratory, Online, and Field Experiments.” Journal of Behavioral and Experimental Finance 9: 88–97. https://doi.org/10.1016/j.jbef.2015.12.001."
  },
  {
    "objectID": "E-online-appendix.html#references",
    "href": "E-online-appendix.html#references",
    "title": "12  Online Appendix E",
    "section": "12.3 References",
    "text": "12.3 References\n\n\n\n\nBaillon, Aurélien, Han Bleichrodt, Umut Keskin, Olivier l’Haridon, and Chen Li. 2017. “The Effect of Learning on Ambiguity Attitudes.” Management Science 64 (5): 2181–98. https://doi.org/10.1287/mnsc.2016.2700.\n\n\nBaillon, Aurélien, Han Bleichrodt, Chen Li, and Peter P. Wakker. 2021. “Belief Hedges: Measuring Ambiguity for All Events and All Models.” Journal of Economic Theory 198: 105353. https://doi.org/10.1016/j.jet.2021.105353.\n\n\nLi, Chen, Uyanga Turmunkh, and Peter P. Wakker. 2019. “Trust as a Decision Under Ambiguity.” Experimental Economics 22: 51–75. https://doi.org/10.1007/s10683-018-9582-3."
  }
]